Experiment 2 ,28_04_2020_02-02-49

Data shape and running
input_shape ,"(28, 28)"
output_shape ,10
scaling ,255.0
epochs ,5
max_runtime,10800
dataset_percentage,1.0
dataset,mnist

Hyper parameters
activation_function ,Activation.relu
initial_max_nodes ,50
loss_function ,Loss.sparse_categorical_crossentropy
optimizer ,Optimizer.Adam

GA parameters
population_size ,10
mating_pool ,10
mutation_rate,0.8

OUTPUT
generation_no,params_no,neurons_no,accuracy,loss
0,37375,47,0.9686,0.10307392459195107
1,44530,56,0.9714,0.1004160184037406
2,41350,52,0.9733,0.09296071836445481
3,43735,55,0.9711,0.09619549342598765
4,53275,67,0.9723,0.08914202151354403
5,53275,67,0.972,0.08828827722226269
6,58045,73,0.9752,0.08677816593591124
7,65200,82,0.9771,0.07608691562651657
8,81100,102,0.976,0.07443746023832355
9,93025,117,0.9778,0.06998212974462659
10,111310,140,0.9754,0.08132406747422646
11,107335,135,0.9785,0.0710290995849762
12,104155,131,0.9762,0.07727010357184336
13,104155,131,0.976,0.08131898277048022
14,124030,156,0.9778,0.06853037440693006
15,147880,186,0.9777,0.07268541954382089
16,155035,195,0.9802,0.06464626607433893
17,191605,241,0.9792,0.07089329019477592
18,191605,241,0.9782,0.07630902501425008
19,212275,267,0.9774,0.07637219987733988
20,271900,342,0.9819,0.06587744144492318
21,309265,389,0.979,0.07985963307466008
22,304495,383,0.9795,0.06958105493906187
23,322780,406,0.9776,0.07243457100602099
24,268720,338,0.9785,0.06983346333595691
25,302110,380,0.978,0.07158500749169616
26,303700,382,0.9803,0.07168146607255912
27,395125,497,0.9804,0.06621527382613858
28,448390,564,0.9798,0.07149771960533108
29,421360,530,0.9791,0.06911919748863438
30,399895,503,0.9789,0.07113926146844751
31,380815,479,0.9821,0.058304729714462884
32,474625,597,0.9814,0.06335816771644168
33,414205,521,0.9797,0.06482249729445902
34,511195,643,0.9782,0.07869055500730465
35,502450,632,0.9798,0.07056113696182147
36,465880,586,0.9795,0.07402465677890287
37,515170,648,0.9803,0.0668724903690978
38,526300,662,0.9805,0.06849139121207991
39,556510,700,0.9791,0.0739964539075765
40,566845,713,0.9819,0.06724438198275165
41,672580,846,0.9832,0.06366061795029891
42,580360,730,0.9778,0.0754436156170792
43,391945,493,0.9788,0.07099227757250191
44,492115,619,0.9799,0.07075145224348525
45,519940,654,0.9822,0.06297390610877773
46,567640,714,0.9768,0.07804826758703712
47,534250,672,0.9806,0.05970058737290092
48,433285,545,0.9802,0.06681845269568439
49,762415,959,0.9812,0.06604955289444915
50,571615,719,0.9754,0.0897351735258766
51,413410,520,0.977,0.07713841810193262
52,823630,1036,0.9765,0.08390460453988052
53,629650,792,0.9803,0.06506626068800979
54,659860,830,0.9824,0.05825360250070225
55,491320,618,0.9787,0.07130662136897153
56,794215,999,0.9775,0.08532111867626663
57,937315,1179,0.9802,0.06595149701864575
58,989785,1245,0.9789,0.07974838841652818
59,933340,1174,0.9789,0.07354884835441043
60,787855,991,0.9776,0.08074531775460927
61,774340,974,0.9822,0.06348827971748251
62,723460,910,0.9792,0.07376379630293231
63,923005,1161,0.9804,0.0738363713728002
64,678145,853,0.9784,0.07685175186744309
65,776725,977,0.98,0.06798533572557498
