Experiment 1 ,04_03_2020_18-37-21

Data shape and running
input_shape ,"(28, 28)"
output_shape ,10
scaling ,255.0
epochs ,5
max_runtime,3600
dataset_percentage,0.1
dataset,mnist

Hyper parameters
activation_function ,Activation.relu
initial_max_nodes ,50
loss_function ,Loss.sparse_categorical_crossentropy
optimizer ,Optimizer.Adam

GA parameters
population_size ,10
mating_pool ,10
mutation_rate,0.3

OUTPUT
generation_no,neurons_no,accuracy,loss
0,43,0.906,0.3009151570796967
1,47,0.906,0.29438532757759095
2,40,0.905,0.2974531683921814
3,59,0.908,0.27746994495391847
4,65,0.909,0.28049612998962403
5,46,0.915,0.28925180625915525
6,74,0.909,0.2925233633518219
7,100,0.911,0.2692325704097748
8,100,0.926,0.2383195812702179
9,100,0.914,0.25841406202316286
10,108,0.914,0.27279567885398864
11,158,0.921,0.2407853903770447
12,145,0.924,0.23909633851051332
13,177,0.93,0.2329165312051773
14,257,0.933,0.21299352431297303
15,97,0.919,0.2560142707824707
16,122,0.919,0.26553538179397584
17,122,0.921,0.2462180154323578
18,108,0.919,0.24094041085243226
19,136,0.922,0.2523974220752716
20,136,0.922,0.24179829382896423
21,144,0.917,0.2418414900302887
22,134,0.923,0.26936276483535765
23,185,0.919,0.2341873791217804
24,185,0.928,0.22711982643604278
25,176,0.925,0.23369717597961426
26,125,0.923,0.23038052582740784
27,200,0.921,0.23670460319519043
28,207,0.926,0.22627240777015686
29,147,0.924,0.24142086410522462
30,161,0.923,0.230668506026268
31,147,0.919,0.25955613899230956
32,128,0.918,0.25623019123077395
33,128,0.915,0.24433954739570618
34,157,0.915,0.26201875758171084
35,130,0.914,0.2567323582172394
36,169,0.922,0.2386061725616455
37,218,0.928,0.2200617699623108
38,260,0.928,0.21290015769004822
39,311,0.927,0.2294163715839386
40,324,0.928,0.21147799557447433
41,363,0.925,0.2185755696296692
42,387,0.929,0.21053711223602295
43,269,0.928,0.20872723245620728
44,346,0.93,0.20580941832065583
45,262,0.929,0.20780164301395415
46,304,0.93,0.2224619336128235
47,335,0.927,0.2014154152870178
48,452,0.925,0.2126999958753586
49,435,0.934,0.21266689920425416
50,707,0.934,0.19032074415683747
51,928,0.939,0.17481158852577208
52,1103,0.928,0.22705846691131593
53,1103,0.938,0.18193086057901384
54,1164,0.929,0.21730436027050018
55,1105,0.944,0.17579474020004274
56,1189,0.938,0.1923081879913807
57,1134,0.941,0.20136417317390443
58,1166,0.939,0.20535983115434647
59,1724,0.951,0.17235963594913484
60,2611,0.937,0.18468266075849532
61,3329,0.93,0.23517605102062225
62,2665,0.945,0.1989178578555584
63,1782,0.943,0.19196323144435884
64,1918,0.937,0.18440704464912414
65,1918,0.944,0.18464285138249398
66,2898,0.942,0.2101663460433483
67,3754,0.939,0.1812544910982251
68,1539,0.939,0.1795929880142212
69,3475,0.941,0.17856726095080375
70,2609,0.943,0.18830373603105546
71,7316,0.943,0.16219899106025695
72,3564,0.95,0.17830896760523318
73,3564,0.944,0.17180286982655527
74,3564,0.945,0.18531792041659356
75,4116,0.948,0.17049248926341534
76,4443,0.934,0.21719830799102782
77,3962,0.953,0.16145017853379248
78,6498,0.936,0.2071153576374054
79,3698,0.948,0.1789621435403824
80,5026,0.939,0.1747234425544739
81,4165,0.939,0.20961899808049203
82,5911,0.929,0.22190598502755166
83,3542,0.944,0.20531198601424694
84,5116,0.946,0.19052854084968568
85,7376,0.946,0.16995032015442849
86,5131,0.939,0.18272386065125465
