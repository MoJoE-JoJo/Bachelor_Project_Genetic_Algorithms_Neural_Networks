Experiment 2 ,05_03_2020_04-31-11

Data shape and running
input_shape ,"(28, 28)"
output_shape ,10
scaling ,255.0
epochs ,5
max_runtime,3600
dataset_percentage,0.1
dataset,mnist

Hyper parameters
activation_function ,Activation.selu
initial_max_nodes ,50
loss_function ,Loss.categorical_crossentropy
optimizer ,Optimizer.SGD

GA parameters
population_size ,10
mating_pool ,10
mutation_rate,0.3

OUTPUT
generation_no,neurons_no,accuracy,loss
0,50,0.854,0.5013973865509033
1,43,0.858,0.4998059997558594
2,58,0.861,0.4927436065673828
3,62,0.867,0.4814465007781982
4,47,0.86,0.5083709106445312
5,41,0.86,0.4892219948768616
6,67,0.869,0.47757805585861207
7,91,0.866,0.46668810749053957
8,85,0.863,0.4910215721130371
9,114,0.867,0.47657080078125
10,160,0.869,0.47148656368255615
11,148,0.865,0.4735063829421997
12,94,0.861,0.49159171533584595
13,153,0.867,0.45138906288146974
14,158,0.867,0.477390456199646
15,81,0.859,0.47547494983673094
16,104,0.878,0.4673331260681152
17,134,0.869,0.4645577006340027
18,134,0.866,0.48040046739578246
19,121,0.871,0.47338108444213867
20,166,0.871,0.46684120750427244
21,164,0.868,0.4597773427963257
22,268,0.872,0.46770271587371826
23,195,0.88,0.4498703255653381
24,196,0.867,0.4600449619293213
25,81,0.874,0.47170573234558105
26,167,0.872,0.46403888750076294
27,100,0.859,0.48193430280685423
28,165,0.871,0.4597988977432251
29,139,0.861,0.4686085081100464
30,161,0.87,0.461908522605896
31,168,0.871,0.4657144541740417
32,132,0.874,0.4632800378799439
33,213,0.862,0.4639847574234009
34,190,0.856,0.4765562982559204
35,154,0.866,0.46767578077316285
36,209,0.867,0.47018196868896484
37,245,0.869,0.4615327739715576
38,360,0.88,0.4407879023551941
39,394,0.873,0.4380509271621704
40,309,0.871,0.457122805595398
41,491,0.875,0.4488200650215149
42,698,0.877,0.4366210708618164
43,993,0.878,0.42670220565795897
44,468,0.873,0.4467747526168823
45,750,0.879,0.4287809629440308
46,750,0.878,0.43568542146682737
47,738,0.87,0.44335031700134275
48,544,0.863,0.44128074407577517
49,1010,0.883,0.4208452501296997
50,695,0.876,0.4351068687438965
51,649,0.875,0.4417718877792358
52,695,0.878,0.4300837092399597
53,1193,0.88,0.4307333660125732
54,1330,0.882,0.4286884150505066
55,1330,0.878,0.42670143270492555
56,1782,0.875,0.42120300483703615
57,1782,0.88,0.42333186292648317
58,1782,0.873,0.42598460721969605
59,2268,0.879,0.41852721738815307
60,2640,0.881,0.4219232659339905
61,3254,0.886,0.41168459320068357
62,3414,0.879,0.41591123151779175
63,4295,0.877,0.41931332111358643
64,2832,0.879,0.41411063480377197
65,2471,0.879,0.4144695606231689
66,3608,0.888,0.41036431884765623
67,4070,0.882,0.41402875375747683
68,5768,0.886,0.4063187961578369
69,1192,0.87,0.4295283050537109
70,2204,0.878,0.4233395457267761
71,2215,0.878,0.4201239614486694
72,3274,0.883,0.4156068406105041
73,1720,0.874,0.4224359736442566
74,3670,0.878,0.41644031047821045
75,3276,0.876,0.41184023666381836
76,3792,0.882,0.41357363414764403
77,4901,0.879,0.41050728368759154
78,6475,0.883,0.4080146689414978
79,8001,0.888,0.4106275062561035
80,6094,0.886,0.4068820190429687
81,6491,0.888,0.40537203788757326
82,6781,0.88,0.40562009716033937
83,9737,0.884,0.4023876576423645
84,5968,0.884,0.4069601311683655
85,6869,0.883,0.4120061159133911
86,8702,0.889,0.4031203227043152
87,8998,0.885,0.4038385829925537
88,16250,0.886,0.4025348844528198
89,8659,0.889,0.4111842246055603
90,23481,0.89,0.3963381404876709
91,20217,0.887,0.39987601470947265
92,12669,0.885,0.40190146207809446
93,16919,0.887,0.40661526012420657
