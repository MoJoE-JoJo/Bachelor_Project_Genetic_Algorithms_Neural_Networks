Experiment 1 ,05_03_2020_03-31-11

Data shape and running
input_shape ,"(28, 28)"
output_shape ,10
scaling ,255.0
epochs ,5
max_runtime,3600
dataset_percentage,0.1
dataset,mnist

Hyper parameters
activation_function ,Activation.selu
initial_max_nodes ,50
loss_function ,Loss.categorical_crossentropy
optimizer ,Optimizer.SGD

GA parameters
population_size ,10
mating_pool ,10
mutation_rate,0.3

OUTPUT
generation_no,neurons_no,accuracy,loss
0,39,0.852,0.5114854030609131
1,34,0.859,0.5229895076751709
2,54,0.859,0.49537828254699706
3,48,0.852,0.5057718987464905
4,66,0.862,0.4906344575881958
5,67,0.862,0.4901363277435303
6,67,0.866,0.4768564748764038
7,88,0.864,0.4765938854217529
8,77,0.862,0.48271419191360476
9,110,0.872,0.47199549961090087
10,147,0.87,0.4645806040763855
11,129,0.868,0.47626518440246585
12,158,0.858,0.4775703382492065
13,93,0.864,0.48388616514205934
14,232,0.862,0.46439558458328245
15,223,0.871,0.45699785137176513
16,330,0.873,0.4383852844238281
17,155,0.875,0.4662491788864136
18,150,0.866,0.4716747045516968
19,143,0.864,0.46544801473617553
20,143,0.868,0.47463073539733885
21,132,0.873,0.47170304822921755
22,225,0.869,0.4542386393547058
23,72,0.868,0.4736400480270386
24,112,0.863,0.47791941785812375
25,115,0.868,0.4711238708496094
26,132,0.864,0.4848237600326538
27,137,0.86,0.4706708755493164
28,123,0.868,0.4682029685974121
29,125,0.868,0.46339091873168947
30,157,0.865,0.46706119203567503
31,149,0.862,0.46809016418457033
32,104,0.87,0.4657115421295166
33,134,0.867,0.4699461131095886
34,164,0.865,0.4748433275222778
35,157,0.858,0.47870799922943114
36,139,0.864,0.481198627948761
37,237,0.874,0.4584459729194641
38,300,0.87,0.4571832332611084
39,311,0.867,0.4515988359451294
40,268,0.874,0.4563292064666748
41,311,0.862,0.4575390405654907
42,389,0.868,0.4494467177391052
43,574,0.869,0.45102628564834596
44,575,0.877,0.44586117553710936
45,1028,0.88,0.4279620089530945
46,490,0.869,0.45273990774154665
47,712,0.876,0.4422118134498596
48,868,0.881,0.4319571032524109
49,394,0.874,0.4415235652923584
50,1227,0.881,0.4209611554145813
51,1227,0.878,0.42595643615722656
52,269,0.871,0.4627262291908264
53,388,0.87,0.44788072633743287
54,287,0.873,0.4505444278717041
55,348,0.87,0.45586730289459226
56,358,0.875,0.44227419471740725
57,542,0.875,0.4345492272377014
58,795,0.879,0.4339504928588867
59,1036,0.877,0.4353002829551697
60,1317,0.879,0.4253486003875732
61,941,0.879,0.4364006915092468
62,1390,0.884,0.4225234770774841
63,1957,0.883,0.4132782716751099
64,1590,0.886,0.41653302097320555
65,2383,0.881,0.41969800424575804
66,2038,0.881,0.4248420486450195
67,736,0.877,0.4334629545211792
68,526,0.871,0.44080772638320925
69,559,0.871,0.44129654741287233
70,786,0.873,0.4385832285881042
71,1037,0.872,0.43480511045455933
72,1037,0.88,0.42789148139953614
73,700,0.874,0.43149979162216184
74,865,0.88,0.4285085535049438
75,633,0.873,0.4438579797744751
76,823,0.875,0.43025291109085084
77,713,0.872,0.44095538997650147
78,744,0.878,0.4357969403266907
79,726,0.867,0.44221882104873655
80,1031,0.88,0.42960873794555665
81,893,0.878,0.4343630056381226
82,1117,0.88,0.42743677139282227
83,1584,0.882,0.4182264652252197
84,2012,0.882,0.41442171573638914
85,2810,0.888,0.41443383741378786
86,3905,0.877,0.41935049200057983
87,1366,0.876,0.430121328830719
88,1366,0.88,0.4306899366378784
89,2499,0.879,0.4144947371482849
90,2421,0.876,0.4214013195037842
91,3245,0.876,0.4165026121139526
92,2845,0.88,0.4211109623908997
93,3717,0.889,0.40903056526184084
94,1467,0.88,0.42210362243652344
95,1773,0.887,0.4170414552688599
96,2466,0.879,0.42475826168060304
97,1972,0.881,0.419609477519989
98,2695,0.88,0.4152911386489868
99,2746,0.877,0.4161367845535278
100,3351,0.884,0.41086487627029417
101,4985,0.884,0.40640417432785036
102,2648,0.882,0.4171639156341553
103,2384,0.885,0.41788301372528075
