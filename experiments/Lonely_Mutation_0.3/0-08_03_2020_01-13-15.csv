Experiment 1 ,08_03_2020_01-13-15

Data shape and running
input_shape ,"(28, 28)"
output_shape ,10
scaling ,255.0
epochs ,5
max_runtime,1800
dataset_percentage,0.1
dataset,mnist

Hyper parameters
activation_function ,Activation.relu
initial_max_nodes ,50
loss_function ,Loss.sparse_categorical_crossentropy
optimizer ,Optimizer.Adam

GA parameters
population_size ,10
mating_pool ,10
mutation_rate,0.3

OUTPUT
generation_no,params_no,neurons_no,accuracy,loss
0,38965,49,0.907,0.302854216337204
1,40555,51,0.917,0.28095878338813784
2,46915,59,0.902,0.293960462808609
3,48505,61,0.912,0.28729995369911193
4,41350,52,0.913,0.2737658576965332
5,43735,55,0.9,0.30473225212097166
6,49300,62,0.916,0.2608231090307236
7,38965,49,0.908,0.28072544527053833
8,34195,43,0.899,0.3242973923683167
9,29425,37,0.913,0.29400792765617373
10,40555,51,0.914,0.27347465562820433
11,27835,35,0.898,0.32834742283821106
12,52480,66,0.917,0.26901706218719484
13,52480,66,0.917,0.2764331464767456
14,58045,73,0.907,0.29516265058517455
15,57250,72,0.917,0.2555271768569946
16,39760,50,0.904,0.29878017854690553
17,35785,45,0.909,0.2786851363182068
18,35785,45,0.903,0.3013068943023682
19,34990,44,0.906,0.2936596608161926
20,31015,39,0.905,0.2981024589538574
21,34195,43,0.901,0.30395941257476805
22,31810,40,0.905,0.30171360564231875
23,34990,44,0.906,0.2858711302280426
24,39760,50,0.919,0.2773286232948303
25,48505,61,0.911,0.2767986147403717
26,48505,61,0.896,0.30310306668281556
27,48505,61,0.907,0.28723099279403685
28,27040,34,0.893,0.3251866507530212
29,30220,38,0.892,0.32316457176208496
30,30220,38,0.903,0.3136810686588287
31,30220,38,0.902,0.30419335079193116
32,24655,31,0.901,0.31551418209075927
33,22270,28,0.901,0.3251297378540039
34,27040,34,0.904,0.31722312259674074
35,18295,23,0.894,0.34768010091781615
36,18295,23,0.892,0.3513415107727051
37,15910,20,0.896,0.34744925594329834
38,15115,19,0.895,0.3425474944114685
39,13525,17,0.897,0.33710600233078003
40,13525,17,0.89,0.36634341192245484
41,11935,15,0.893,0.3633441119194031
42,12730,16,0.884,0.3807544360160828
43,15910,20,0.893,0.35098892402648924
44,19885,25,0.908,0.3140749955177307
45,23860,30,0.895,0.325883713722229
46,28630,36,0.9,0.30440278244018554
47,28630,36,0.902,0.32341106224060057
48,32605,41,0.911,0.30513004302978514
49,29425,37,0.894,0.3243652856349945
50,29425,37,0.898,0.3137174882888794
51,29425,37,0.903,0.30522093653678894
52,32605,41,0.896,0.3267428569793701
53,41350,52,0.905,0.300758011341095
54,20680,26,0.898,0.34399416732788085
55,23065,29,0.905,0.31032289123535156
56,29425,37,0.905,0.31085865688323977
57,29425,37,0.897,0.30917400550842283
58,37375,47,0.907,0.286097713470459
59,41350,52,0.909,0.3016920528411865
60,38965,49,0.91,0.294439338684082
61,41350,52,0.906,0.29650947070121764
62,47710,60,0.909,0.2734090940952301
63,46120,58,0.912,0.272769152879715
64,45325,57,0.91,0.274647970199585
65,52480,66,0.912,0.2711114068031311
66,46120,58,0.909,0.28534748101234436
67,48505,61,0.911,0.29372068667411805
68,51685,65,0.909,0.27697428774833677
69,58840,74,0.908,0.2855923104286194
70,63610,80,0.922,0.2633399422168732
71,58045,73,0.917,0.2745386445522308
72,46915,59,0.905,0.2971545009613037
73,52480,66,0.9,0.28705771565437316
74,39760,50,0.913,0.2802797739505768
75,48505,61,0.904,0.28980666542053224
76,52480,66,0.918,0.260539041519165
77,60430,76,0.9,0.2849632887840271
78,61225,77,0.914,0.26436019444465636
79,73150,92,0.911,0.27838046646118164
80,54865,69,0.915,0.27506593155860903
81,66790,84,0.913,0.25803204655647277
82,66790,84,0.913,0.2718841903209686
83,40555,51,0.907,0.29360968017578126
84,34195,43,0.91,0.2818441796302795
85,28630,36,0.911,0.2925850555896759
86,46120,58,0.901,0.29378399229049684
