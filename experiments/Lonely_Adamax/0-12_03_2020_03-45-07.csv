Experiment 1 ,12_03_2020_03-45-07

Data shape and running
input_shape ,"(28, 28)"
output_shape ,10
scaling ,255.0
epochs ,5
max_runtime,1800
dataset_percentage,0.1
dataset,mnist

Hyper parameters
activation_function ,Activation.relu
initial_max_nodes ,50
loss_function ,Loss.sparse_categorical_crossentropy
optimizer ,Optimizer.Adamax

GA parameters
population_size ,10
mating_pool ,10
mutation_rate,0.2

OUTPUT
generation_no,params_no,neurons_no,accuracy,loss
0,33400,42,0.883,0.38771402883529665
1,35785,45,0.885,0.3984487328529358
2,35785,45,0.888,0.3964376006126404
3,36580,46,0.884,0.4008271932601929
4,42145,53,0.893,0.38380206394195554
5,34195,43,0.882,0.41560106992721557
6,32605,41,0.889,0.3920362753868103
7,46120,58,0.89,0.3816995658874512
8,44530,56,0.886,0.3843408169746399
9,48505,61,0.89,0.3772830333709717
10,48505,61,0.888,0.3752844567298889
11,22270,28,0.877,0.4323564014434814
12,23065,29,0.88,0.4303408727645874
13,22270,28,0.876,0.44700405216217043
14,23065,29,0.881,0.4297222747802734
15,22270,28,0.872,0.454901819229126
16,22270,28,0.881,0.4432219786643982
17,20680,26,0.877,0.4327068147659302
18,27040,34,0.871,0.4211105890274048
19,26245,33,0.874,0.43595483016967773
20,23065,29,0.878,0.432720263004303
21,24655,31,0.879,0.43181022930145263
22,27835,35,0.88,0.42406138467788695
23,27040,34,0.878,0.41396096992492676
24,32605,41,0.882,0.4105178761482239
25,23065,29,0.878,0.4276587438583374
26,22270,28,0.876,0.4400692768096924
27,22270,28,0.875,0.43953519344329833
28,25450,32,0.873,0.44369495296478273
29,25450,32,0.875,0.4346877880096435
30,26245,33,0.879,0.42829720401763915
31,21475,27,0.881,0.43684471607208253
32,26245,33,0.883,0.4216024260520935
33,32605,41,0.883,0.39465488243103025
34,41350,52,0.889,0.3893905129432678
35,40555,51,0.879,0.3974230604171753
36,44530,56,0.882,0.39096497297286986
37,43735,55,0.88,0.39335691928863525
38,24655,31,0.875,0.42327322673797607
39,29425,37,0.879,0.4163350863456726
40,35785,45,0.892,0.3968115968704224
41,35785,45,0.885,0.41447867107391356
42,39760,50,0.879,0.38911760711669924
43,57250,72,0.897,0.36265924406051636
44,48505,61,0.891,0.3738417730331421
45,31015,39,0.892,0.4027881226539612
46,26245,33,0.878,0.41890894985198973
47,32605,41,0.883,0.4130617456436157
48,37375,47,0.883,0.4051262974739075
49,32605,41,0.886,0.39715798711776734
50,42145,53,0.883,0.3944704518318176
51,32605,41,0.883,0.4041445174217224
52,38170,48,0.887,0.3929442410469055
53,34990,44,0.881,0.4114192361831665
54,34990,44,0.891,0.387539719581604
55,38170,48,0.889,0.39305203437805175
56,43735,55,0.892,0.3922625226974487
57,44530,56,0.893,0.3750920763015747
58,45325,57,0.888,0.3774457068443298
59,42940,54,0.891,0.3838389129638672
60,42940,54,0.89,0.3791201434135437
61,28630,36,0.878,0.43145492219924925
62,20680,26,0.876,0.4389363965988159
63,20680,26,0.877,0.4507903094291687
64,24655,31,0.875,0.43428983783721925
65,24655,31,0.866,0.44987839269638064
66,31015,39,0.872,0.4259067544937134
67,31015,39,0.885,0.4121013374328613
68,31015,39,0.889,0.39749062538146973
69,34195,43,0.882,0.4061965584754944
70,34990,44,0.875,0.40478517913818357
71,35785,45,0.877,0.3970762701034546
72,27835,35,0.887,0.40357673597335814
73,34990,44,0.895,0.4041935658454895
74,27835,35,0.881,0.40994231367111206
75,30220,38,0.887,0.40520915842056277
76,35785,45,0.889,0.39739919567108156
77,25450,32,0.873,0.43231036853790283
78,25450,32,0.869,0.43506302785873413
79,31810,40,0.88,0.41079375648498534
80,29425,37,0.873,0.42372018146514895
81,40555,51,0.891,0.38480223894119264
82,40555,51,0.887,0.39639427185058596
83,33400,42,0.881,0.4077421522140503
84,31810,40,0.885,0.3960274829864502
85,33400,42,0.881,0.40304198932647706
86,32605,41,0.882,0.41763781499862673
87,27835,35,0.881,0.4200026631355286
88,27835,35,0.883,0.40891222858428955
89,30220,38,0.879,0.4319536848068237
