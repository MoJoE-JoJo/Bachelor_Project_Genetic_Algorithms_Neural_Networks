Experiment 2 ,12_03_2020_03-15-06

Data shape and running
input_shape ,"(28, 28)"
output_shape ,10
scaling ,255.0
epochs ,5
max_runtime,1800
dataset_percentage,0.1
dataset,mnist

Hyper parameters
activation_function ,Activation.relu
initial_max_nodes ,50
loss_function ,Loss.sparse_categorical_crossentropy
optimizer ,Optimizer.Nadam

GA parameters
population_size ,10
mating_pool ,10
mutation_rate,0.2

OUTPUT
generation_no,params_no,neurons_no,accuracy,loss
0,30220,38,0.901,0.30754885149002076
1,44530,56,0.902,0.2971175940036774
2,44530,56,0.901,0.2935376195907593
3,38170,48,0.913,0.29676110339164735
4,42940,54,0.917,0.2708469760417938
5,50095,63,0.91,0.29969935297966005
6,54865,69,0.906,0.31894775009155274
7,68380,86,0.909,0.28071632599830626
8,81100,102,0.917,0.2554905438423157
9,41350,52,0.908,0.2861165428161621
10,31810,40,0.909,0.3097096438407898
11,35785,45,0.907,0.2952421088218689
12,27040,34,0.899,0.29826683568954465
13,24655,31,0.908,0.30571579504013063
14,33400,42,0.908,0.3021890754699707
15,30220,38,0.907,0.2979201216697693
16,36580,46,0.91,0.28348794054985044
17,27835,35,0.898,0.321218948841095
18,32605,41,0.907,0.29759693789482117
19,23065,29,0.903,0.3037659974098206
20,42145,53,0.907,0.2892917807102203
21,25450,32,0.907,0.2993185427188873
22,32605,41,0.904,0.3205632038116455
23,40555,51,0.901,0.2817500967979431
24,49300,62,0.911,0.2917169489860535
25,24655,31,0.903,0.313334602355957
26,29425,37,0.914,0.30297710990905763
27,30220,38,0.907,0.3073769359588623
28,28630,36,0.906,0.31133959484100343
29,23065,29,0.9,0.31757981491088866
30,27835,35,0.91,0.2876164925098419
31,34195,43,0.905,0.3034233100414276
32,29425,37,0.895,0.3114676012992859
33,36580,46,0.913,0.27905815505981446
34,45325,57,0.899,0.293064546585083
35,54070,68,0.908,0.27393650078773496
36,64405,81,0.908,0.2809761765003204
37,77920,98,0.919,0.2526745090484619
38,77920,98,0.917,0.24928172874450683
39,68380,86,0.909,0.2684685642719269
40,51685,65,0.909,0.282116703748703
41,50890,64,0.909,0.27174069714546206
42,53275,67,0.909,0.2999173450469971
43,57250,72,0.913,0.26659825825691225
44,60430,76,0.912,0.26619121885299685
45,60430,76,0.913,0.26063501977920533
46,66790,84,0.911,0.25978035235404967
47,57250,72,0.906,0.2762949204444885
48,48505,61,0.91,0.2737801029682159
49,53275,67,0.925,0.24875983119010925
50,50095,63,0.918,0.26655938720703126
51,59635,75,0.911,0.2732022702693939
52,76330,96,0.908,0.28541291880607605
53,65995,83,0.899,0.27891591811180116
54,66790,84,0.911,0.278256952047348
55,77920,98,0.915,0.25976918697357176
56,94615,119,0.912,0.2707909734249115
57,77920,98,0.908,0.2691212911605835
58,76330,96,0.907,0.27779846215248105
59,85870,108,0.921,0.25947681522369387
60,69175,87,0.918,0.2609125053882599
61,93025,117,0.92,0.2472604706287384
62,79510,100,0.913,0.2537344355583191
63,81895,103,0.919,0.263960289478302
64,115285,145,0.919,0.25289640402793884
65,93025,117,0.919,0.2592863123416901
66,93025,117,0.913,0.25843088555335997
