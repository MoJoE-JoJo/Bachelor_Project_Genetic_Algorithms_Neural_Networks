Experiment 2 ,07_03_2020_18-17-01

Data shape and running
input_shape ,"(28, 28)"
output_shape ,10
scaling ,255.0
epochs ,5
max_runtime,1800
dataset_percentage,0.1
dataset,mnist

Hyper parameters
activation_function ,Activation.relu
initial_max_nodes ,50
loss_function ,Loss.sparse_categorical_crossentropy
optimizer ,Optimizer.Adam

GA parameters
population_size ,10
mating_pool ,10
mutation_rate,0.1

OUTPUT
generation_no,params_no,neurons_no,accuracy,loss
0,39760,50,0.911,0.2807165613174438
1,38170,48,0.911,0.2803263032436371
2,31015,39,0.905,0.29948895478248594
3,34195,43,0.899,0.31538360691070555
4,32605,41,0.895,0.31976321363449095
5,21475,27,0.899,0.329793000459671
6,19885,25,0.89,0.35010112237930296
7,13525,17,0.882,0.36649681138992307
8,15910,20,0.891,0.3552566695213318
9,15910,20,0.902,0.33741986846923827
10,16705,21,0.896,0.34277345609664917
11,18295,23,0.909,0.3248687937259674
12,22270,28,0.903,0.3252545742988586
13,21475,27,0.9,0.3381603956222534
14,17500,22,0.897,0.33974078798294066
15,5575,7,0.87,0.47146089124679563
16,7165,9,0.862,0.4245426025390625
17,7960,10,0.873,0.4128246650695801
18,9550,12,0.884,0.3784038624763489
19,11935,15,0.893,0.37980013942718505
20,12730,16,0.88,0.3691929025650024
21,12730,16,0.89,0.35523381185531616
22,13525,17,0.895,0.3513868045806885
23,12730,16,0.885,0.37301137018203734
24,13525,17,0.884,0.36359022665023805
25,11935,15,0.885,0.3706153507232666
26,13525,17,0.892,0.3666362669467926
27,15115,19,0.895,0.3527938303947449
28,15910,20,0.889,0.3498647179603577
29,15115,19,0.905,0.3297835385799408
30,17500,22,0.902,0.3300800886154175
31,22270,28,0.9,0.33151972508430483
32,21475,27,0.897,0.3282268478870392
33,21475,27,0.912,0.3144783957004547
34,19885,25,0.898,0.33999577379226686
35,19885,25,0.9,0.3379285583496094
36,24655,31,0.905,0.330076464176178
37,23065,29,0.907,0.319836884021759
38,24655,31,0.909,0.3225948181152344
39,28630,36,0.903,0.32012980651855466
40,33400,42,0.905,0.2991177496910095
41,42145,53,0.913,0.29349081325531007
42,40555,51,0.913,0.27946249437332155
43,51685,65,0.921,0.2712171926498413
44,40555,51,0.911,0.28287362480163575
45,33400,42,0.895,0.30282747077941896
46,38965,49,0.901,0.2941622531414032
47,55660,70,0.911,0.28206398129463195
48,48505,61,0.908,0.2904950547218323
49,40555,51,0.906,0.2728844745159149
50,46120,58,0.911,0.294641432762146
51,35785,45,0.897,0.3165091896057129
52,9550,12,0.876,0.4065164322853088
53,10345,13,0.885,0.3928281149864197
54,11935,15,0.889,0.3971729426383972
55,11140,14,0.881,0.368636278629303
56,12730,16,0.884,0.35689774990081785
57,10345,13,0.896,0.3472282824516296
58,11935,15,0.892,0.3498587121963501
59,11935,15,0.882,0.36665634632110594
60,11140,14,0.889,0.3734196448326111
61,9550,12,0.884,0.3765741405487061
62,11140,14,0.881,0.3770068507194519
63,11935,15,0.896,0.35358710622787476
64,11935,15,0.895,0.35855544185638427
65,13525,17,0.888,0.3700219316482544
66,10345,13,0.89,0.3690629954338074
67,11140,14,0.895,0.3543882122039795
68,11140,14,0.884,0.3778381423950195
69,11140,14,0.892,0.3602123112678528
70,11140,14,0.884,0.40129302263259886
71,7960,10,0.871,0.42728308296203615
72,8755,11,0.872,0.42812102270126345
73,9550,12,0.887,0.3785246689319611
74,7960,10,0.885,0.41630418920516965
75,7165,9,0.852,0.48691937351226805
76,3985,5,0.772,0.7075371761322021
77,4780,6,0.81,0.6084053897857666
78,4780,6,0.817,0.610472487449646
79,5575,7,0.827,0.5656996135711669
80,6370,8,0.875,0.4308438248634338
81,7165,9,0.868,0.42201384830474853
82,7960,10,0.873,0.4262834930419922
83,8755,11,0.882,0.3936066436767578
84,7165,9,0.868,0.4295446376800537
85,8755,11,0.878,0.3855473439693451
86,7165,9,0.873,0.42728933000564573
87,7960,10,0.891,0.3738464379310608
