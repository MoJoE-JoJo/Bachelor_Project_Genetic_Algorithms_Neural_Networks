Experiment 2 ,07_03_2020_19-47-02

Data shape and running
input_shape ,"(28, 28)"
output_shape ,10
scaling ,255.0
epochs ,5
max_runtime,1800
dataset_percentage,0.1
dataset,mnist

Hyper parameters
activation_function ,Activation.relu
initial_max_nodes ,50
loss_function ,Loss.sparse_categorical_crossentropy
optimizer ,Optimizer.Adam

GA parameters
population_size ,10
mating_pool ,10
mutation_rate,0.2

OUTPUT
generation_no,params_no,neurons_no,accuracy,loss
0,37375,47,0.903,0.29932685327529907
1,42940,54,0.907,0.29235521697998046
2,38170,48,0.908,0.2821976191997528
3,46120,58,0.914,0.28040824508666995
4,42145,53,0.912,0.2820280873775482
5,62020,78,0.911,0.2636505672931671
6,62020,78,0.903,0.27714751148223876
7,62020,78,0.911,0.26919955945014956
8,55660,70,0.912,0.26298237943649294
9,65200,82,0.916,0.2639855453968048
10,80305,101,0.924,0.24355737698078156
11,81100,102,0.914,0.25832893085479736
12,99385,125,0.921,0.25746024203300477
13,99385,125,0.919,0.25511764311790464
14,62020,78,0.916,0.2662661118507385
15,82690,104,0.919,0.2753660595417023
16,79510,100,0.921,0.2651009986400604
17,92230,116,0.911,0.2666691858768463
18,110515,139,0.925,0.22917812597751616
19,116080,146,0.913,0.24537772059440613
20,101770,128,0.925,0.2415657606124878
21,131185,165,0.924,0.24719410371780395
22,129595,163,0.925,0.2475662120580673
23,112900,142,0.925,0.2579612669944763
24,116080,146,0.924,0.238793518781662
25,118465,149,0.918,0.26870064187049864
26,116875,147,0.923,0.23506933319568635
27,127210,160,0.915,0.25605792975425723
28,127210,160,0.918,0.24397040057182312
29,174115,219,0.926,0.2249000370502472
30,191605,241,0.926,0.2356801427602768
31,201145,253,0.915,0.23499609065055846
32,192400,242,0.926,0.22060945320129394
33,232150,292,0.924,0.2323453849554062
34,188425,237,0.927,0.22526208674907686
35,221020,278,0.92,0.24231015062332154
36,267130,336,0.925,0.2146901124715805
37,295750,372,0.934,0.20581509947776794
38,290980,366,0.933,0.2095754263997078
39,306085,385,0.93,0.21596406960487366
40,306085,385,0.932,0.20579881405830383
41,276670,348,0.927,0.20987876904010772
42,312445,393,0.935,0.204337109208107
43,352990,444,0.94,0.19148782640695572
44,290980,366,0.934,0.20624448120594024
45,320395,403,0.935,0.2023749393224716
46,320395,403,0.916,0.23284201085567474
47,361735,455,0.933,0.20458236956596373
48,312445,393,0.924,0.20605982732772826
49,312445,393,0.929,0.21511493802070616
50,324370,408,0.941,0.1937591065168381
51,395920,498,0.931,0.19683631157875062
52,466675,587,0.938,0.20210486471652986
53,466675,587,0.929,0.21418987846374513
54,345835,435,0.939,0.19650610363483428
55,413410,520,0.914,0.23309004706144332
56,554920,698,0.939,0.18230713939666748
57,329935,415,0.931,0.20957010638713836
58,405460,510,0.938,0.18229178607463836
59,405460,510,0.93,0.21057266175746917
60,405460,510,0.931,0.20385615742206573
61,424540,534,0.932,0.20539261555671692
62,511990,644,0.931,0.19473213493824004
63,613750,772,0.938,0.19998772311210633
64,783880,986,0.936,0.1847822334766388
65,647140,814,0.939,0.20038217598199845
66,771160,970,0.929,0.20269163811206817
67,787060,990,0.943,0.18052246582508086
68,614545,773,0.931,0.2058688012957573
69,302110,380,0.934,0.21597481989860534
70,277465,349,0.928,0.20218368756771088
71,390355,491,0.941,0.18639711260795594
72,446005,561,0.927,0.19834004354476928
73,348220,438,0.932,0.2097478654384613
74,403870,508,0.932,0.20334794974327086
75,352195,443,0.937,0.210342960357666
76,450775,567,0.934,0.19730797624588012
77,421360,530,0.93,0.19622700417041777
78,477010,600,0.931,0.21467578959465028
79,589105,741,0.931,0.19873271572589873
80,589105,741,0.936,0.20579896235466003
81,705175,887,0.947,0.19317154788970947
82,523120,658,0.932,0.20470892548561095
83,655090,824,0.934,0.21885676181316377
84,814885,1025,0.932,0.2034127796292305
85,804550,1012,0.936,0.20881280666589738
