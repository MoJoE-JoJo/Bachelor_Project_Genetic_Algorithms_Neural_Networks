Experiment 1 ,06_04_2020_00-50-22

Data shape and running
input_shape ,"(28, 28)"
output_shape ,10
scaling ,255.0
epochs ,5
max_runtime,10800
dataset_percentage,1.0
dataset,mnist

Hyper parameters
activation_function ,Activation.relu
initial_max_nodes ,50
loss_function ,Loss.sparse_categorical_crossentropy
optimizer ,Optimizer.Adam

GA parameters
population_size ,10
mating_pool ,10
mutation_rate,0.8

OUTPUT
generation_no,params_no,neurons_no,accuracy,loss
0,35785,45,0.9712,0.09608776034675538
1,44530,56,0.9726,0.09568533589299769
2,44530,56,0.9713,0.09514096021377481
3,50890,64,0.9726,0.08686129071554169
4,58840,74,0.972,0.09452746668057516
5,53275,67,0.974,0.08422468028077856
6,49300,62,0.9715,0.09133913016011938
7,62815,79,0.9755,0.07922971846922301
8,69970,88,0.9726,0.09224853927060031
9,43735,55,0.9688,0.09722855791952462
10,55660,70,0.9729,0.08553489968804642
11,66790,84,0.9763,0.07810521012647077
12,85075,107,0.978,0.07757236641459167
13,108130,136,0.9777,0.07506142148091458
14,135160,170,0.9781,0.0743916384628974
15,159805,201,0.9767,0.07051589416706702
16,177295,223,0.9807,0.061756517863762565
17,224995,283,0.9783,0.07280644474991714
18,224995,283,0.9784,0.070025250317459
19,162190,204,0.9795,0.0679912481740932
20,143110,180,0.9777,0.07408007196853869
21,177295,223,0.9799,0.06250152363483794
22,187630,236,0.9807,0.06253252906801644
23,166960,210,0.9772,0.07536842601827812
24,139135,175,0.9768,0.0769985003906535
25,159010,200,0.9782,0.07164147514633369
26,128800,162,0.9786,0.06883105048643193
27,121645,153,0.9733,0.0843113215199206
28,96205,121,0.9762,0.0799236139350105
29,120055,151,0.9758,0.08077246683547273
30,144700,182,0.9758,0.08081169686014764
31,143905,181,0.9782,0.07164628308888059
32,116080,146,0.9727,0.08600575830014423
33,119260,150,0.9761,0.0831398594840197
34,123235,155,0.9738,0.07930380898993462
35,107335,135,0.9774,0.07243580217158888
36,64405,81,0.9732,0.08862000709166751
37,67585,85,0.9747,0.08373792982320301
38,74740,94,0.9777,0.07275531816440635
39,73150,92,0.9714,0.0976632654982619
40,73945,93,0.9738,0.08256737867724151
41,73150,92,0.9759,0.07821906005670316
42,75535,95,0.9696,0.0928820377937518
43,82690,104,0.972,0.0893246884261258
44,105745,133,0.9775,0.07258052137224004
45,136750,172,0.9711,0.09099744329415262
46,137545,173,0.9762,0.07938685385033023
47,164575,207,0.9788,0.0715189384653233
48,192400,242,0.979,0.07233322666327004
49,192400,242,0.9758,0.0761417215237394
50,228970,288,0.9784,0.07160467601182172
51,99385,125,0.9756,0.07879331765505486
52,96205,121,0.9774,0.07337993358573876
53,108130,136,0.9782,0.07359018293600529
54,97000,122,0.9778,0.07206735848020762
55,97000,122,0.9752,0.08047982637279201
56,86665,109,0.9749,0.08314315970651806
57,64405,81,0.9727,0.09329690118441358
58,81895,103,0.975,0.0837743998075137
59,72355,91,0.9715,0.09396502528479322
60,55660,70,0.9762,0.08093003459018655
61,57250,72,0.9738,0.08537064707595855
62,56455,71,0.9741,0.08651008734889329
63,69175,87,0.9765,0.07680519082196988
64,68380,86,0.9761,0.08046147018361371
65,85870,108,0.9757,0.07710548099409789
66,75535,95,0.9745,0.08274947295584716
67,82690,104,0.9718,0.0929955990930088
68,86665,109,0.9751,0.07959999578548595
69,85075,107,0.9739,0.08480891178715974
70,102565,129,0.9744,0.07647009938370902
71,130390,164,0.9792,0.06607159074672964
