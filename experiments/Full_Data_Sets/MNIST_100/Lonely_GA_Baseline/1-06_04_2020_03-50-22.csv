Experiment 2 ,06_04_2020_03-50-22

Data shape and running
input_shape ,"(28, 28)"
output_shape ,10
scaling ,255.0
epochs ,5
max_runtime,10800
dataset_percentage,1.0
dataset,mnist

Hyper parameters
activation_function ,Activation.relu
initial_max_nodes ,50
loss_function ,Loss.sparse_categorical_crossentropy
optimizer ,Optimizer.Adam

GA parameters
population_size ,10
mating_pool ,10
mutation_rate,0.8

OUTPUT
generation_no,params_no,neurons_no,accuracy,loss
0,37375,47,0.9669,0.1069546493561007
1,37375,47,0.9683,0.1026070139342919
2,33400,42,0.9686,0.10492494391743094
3,31015,39,0.966,0.1133626720160246
4,37375,47,0.9698,0.09854851143765263
5,46120,58,0.9718,0.09274215557761491
6,57250,72,0.9748,0.08508650422203355
7,53275,67,0.9738,0.0893751422967296
8,57250,72,0.9729,0.09598574598347769
9,57250,72,0.974,0.08373855464025401
10,71560,90,0.9751,0.08107727251988836
11,62815,79,0.9735,0.08532159297419711
12,78715,99,0.9789,0.07133538486794569
13,71560,90,0.9753,0.07922322923261672
14,10345,13,0.94,0.20422163140326738
15,11935,15,0.9457,0.1903946329087019
16,11140,14,0.9401,0.20200096221268177
17,11140,14,0.943,0.2017134292319417
18,11140,14,0.943,0.19607374128401278
19,11935,15,0.9412,0.2007376045025885
20,13525,17,0.9536,0.1680232796229422
21,15115,19,0.9526,0.16529550596773623
22,19090,24,0.9584,0.14549742778092623
23,17500,22,0.9561,0.14750977990701794
24,17500,22,0.9551,0.15819326464235783
25,19885,25,0.9601,0.12841132609397174
26,19885,25,0.9591,0.1343833132956177
27,18295,23,0.9586,0.13780575550198554
28,22270,28,0.961,0.13031213344149292
29,22270,28,0.9617,0.12679536938816308
30,27835,35,0.9628,0.1260899727962911
31,27040,34,0.9606,0.13183372868597507
32,27040,34,0.9637,0.12027989866854623
33,27040,34,0.9656,0.10700833405833692
34,30220,38,0.9654,0.11205081535689533
35,31810,40,0.9699,0.10583935896903277
36,34990,44,0.9653,0.1115028281390667
37,34990,44,0.9656,0.1150559531852603
38,39760,50,0.9699,0.09694370065368713
39,50095,63,0.9735,0.09016856945678592
40,55660,70,0.9701,0.09663766054920853
41,62815,79,0.9688,0.09753259030357003
42,76330,96,0.9777,0.07496155947251246
43,84280,106,0.9768,0.07692478524362668
44,91435,115,0.9788,0.06990794350337237
45,62815,79,0.9744,0.08740194823490456
46,62815,79,0.9752,0.085219801214803
47,62815,79,0.973,0.0869395333172055
48,75535,95,0.9754,0.08109801375870593
49,70765,89,0.9634,0.11048430766547099
50,89845,113,0.9764,0.0800560180308763
51,73945,93,0.9762,0.0773048315639142
52,73945,93,0.9745,0.08451872258894146
53,78715,99,0.9753,0.08009494498539715
54,85075,107,0.9718,0.08934451861083507
55,41350,52,0.9721,0.09212252966146917
56,36580,46,0.9679,0.10450078687816858
57,42145,53,0.9701,0.10156657078936696
58,42145,53,0.9692,0.09922666819356382
59,43735,55,0.9694,0.09929057361511513
60,42940,54,0.9702,0.09912360734818504
61,54070,68,0.9732,0.08756086080083623
62,60430,76,0.9749,0.07880649760281667
63,65995,83,0.9741,0.0852276547074318
64,72355,91,0.9717,0.09626033727303147
65,79510,100,0.9745,0.08724263871689326
66,100180,126,0.9765,0.07872017475017347
67,78715,99,0.975,0.0837036218076013
68,67585,85,0.9755,0.08300072217425332
69,64405,81,0.9703,0.09551116512920707
70,65995,83,0.9753,0.08016136564598418
71,52480,66,0.9743,0.08528422700925731
