Experiment 1 ,09_05_2020_00-26-10

Data shape and running
input_shape ,"(28, 28)"
output_shape ,10
scaling ,255.0
epochs ,5
max_runtime,10800
dataset_percentage,1.0
dataset,fashion_mnist

Hyper parameters
activation_function ,Activation.relu
initial_max_nodes ,50
loss_function ,Loss.sparse_categorical_crossentropy
optimizer ,Optimizer.Adam

GA parameters
population_size ,10
mating_pool ,10
mutation_rate,0.8

OUTPUT
generation_no,params_no,neurons_no,accuracy,loss
0,39760,50,0.8606,0.38722681362628936
1,39760,50,0.8739,0.362576509809494
2,34195,43,0.8592,0.4051588594913483
3,37375,47,0.8671,0.3777872853755951
4,37375,47,0.867,0.36995243067741396
5,46915,59,0.8709,0.36711426651477813
6,24655,31,0.8585,0.38738176209926606
7,27040,34,0.864,0.38255362886190414
8,30220,38,0.8669,0.3792275935649872
9,34990,44,0.8706,0.3670218563079834
10,21475,27,0.8626,0.3902532491445541
11,19885,25,0.857,0.4013241979598999
12,18295,23,0.8557,0.4145240014076233
13,14320,18,0.8528,0.40699987186193465
14,19885,25,0.8461,0.4179689079761505
15,19885,25,0.8619,0.3945036234378815
16,13525,17,0.8508,0.43082684462070464
17,13525,17,0.8523,0.41939626972675326
18,15910,20,0.8488,0.4325905960083008
19,19090,24,0.8455,0.43127542848587036
20,23065,29,0.8675,0.3742898384094238
21,25450,32,0.8607,0.3847842430472374
22,29425,37,0.8633,0.37929266440868376
23,34990,44,0.8633,0.38138859221935273
24,25450,32,0.8631,0.38691566863059995
25,24655,31,0.8541,0.40507421219348905
26,27835,35,0.8585,0.3895508409500122
27,27835,35,0.8583,0.3978366113185883
28,30220,38,0.8578,0.3936494607925415
29,25450,32,0.8497,0.4340572288274765
30,21475,27,0.8526,0.4101673526287079
31,21475,27,0.8599,0.40433292055130005
32,10345,13,0.8533,0.4206345424890518
33,11140,14,0.8509,0.4263252417802811
34,11935,15,0.8549,0.4189725018262863
35,11140,14,0.8471,0.4417827325344086
36,10345,13,0.8473,0.4367649786710739
37,15115,19,0.8583,0.39715742390155795
38,17500,22,0.8542,0.41669683091640475
39,13525,17,0.8552,0.41910520544052127
40,15910,20,0.8574,0.4006597306251526
41,15910,20,0.8584,0.40628988103866576
42,15115,19,0.858,0.39961106650829314
43,15910,20,0.8514,0.41760568268299103
44,10345,13,0.8483,0.4281329864740372
45,11935,15,0.8488,0.4250027282476425
46,11935,15,0.8504,0.427348352766037
47,15115,19,0.8551,0.4065794071674347
48,11935,15,0.8504,0.4293245528459549
49,15115,19,0.8482,0.4354260037660599
50,18295,23,0.8431,0.43415587775707243
51,19885,25,0.8543,0.40823897573947904
52,19090,24,0.8597,0.4012313061475754
53,25450,32,0.87,0.36523432232141495
54,25450,32,0.8594,0.39494147086143494
55,22270,28,0.8543,0.4133908406019211
56,16705,21,0.847,0.4392135751724243
57,10345,13,0.854,0.41889156694412233
58,10345,13,0.8497,0.4392408933162689
59,17500,22,0.8491,0.43003414301872256
60,9550,12,0.8499,0.4321233193874359
61,12730,16,0.8483,0.4246670315980911
62,5575,7,0.8368,0.46377344722747804
63,9550,12,0.8471,0.4392462687253952
64,7960,10,0.8481,0.43081793348789216
65,7960,10,0.8433,0.44388344225883486
66,7165,9,0.8337,0.46922370433807375
67,8755,11,0.8547,0.4234064858436584
68,8755,11,0.8447,0.438155465722084
69,9550,12,0.8477,0.428186870598793
70,11935,15,0.847,0.4398021160364151
71,13525,17,0.841,0.44196167685985566
