Experiment 2 ,09_05_2020_03-26-10

Data shape and running
input_shape ,"(28, 28)"
output_shape ,10
scaling ,255.0
epochs ,5
max_runtime,10800
dataset_percentage,1.0
dataset,fashion_mnist

Hyper parameters
activation_function ,Activation.relu
initial_max_nodes ,50
loss_function ,Loss.sparse_categorical_crossentropy
optimizer ,Optimizer.Adam

GA parameters
population_size ,10
mating_pool ,10
mutation_rate,0.8

OUTPUT
generation_no,params_no,neurons_no,accuracy,loss
0,33400,42,0.8686,0.36853793647289274
1,32605,41,0.8672,0.3840426240682602
2,41350,52,0.8639,0.37313427295684815
3,41350,52,0.8698,0.361940789437294
4,43735,55,0.8669,0.37058860063552856
5,54865,69,0.8727,0.35250348386764524
6,64405,81,0.8754,0.3474636464834213
7,80305,101,0.8712,0.3561349800825119
8,21475,27,0.8532,0.4150143185138702
9,23065,29,0.8652,0.37976605122089385
10,23065,29,0.863,0.3917171632766724
11,24655,31,0.8517,0.42374901535511017
12,25450,32,0.8537,0.4022452863931656
13,29425,37,0.861,0.3822578673362732
14,33400,42,0.8685,0.36695746121406553
15,39760,50,0.8685,0.3641952085256577
16,42940,54,0.8679,0.36900687117576597
17,44530,56,0.8708,0.3658773629665375
18,45325,57,0.8683,0.365577627491951
19,39760,50,0.8698,0.3654840847015381
20,55660,70,0.8732,0.3565506507277489
21,69970,88,0.8707,0.359342698264122
22,70765,89,0.8689,0.3570955904841423
23,73945,93,0.8751,0.35932061042785646
24,62020,78,0.8705,0.3585760980606079
25,76330,96,0.8755,0.3489759019970894
26,71560,90,0.8725,0.3631300503253937
27,92230,116,0.8787,0.3415831448316574
28,100180,126,0.8662,0.37003888721466066
29,124030,156,0.8634,0.3845329660177231
30,85075,107,0.8627,0.3800686566948891
31,77125,97,0.8769,0.3515665048360825
32,85075,107,0.852,0.3944360887527466
33,93025,117,0.876,0.349146963763237
34,113695,143,0.8712,0.36903185105323794
35,134365,169,0.8784,0.34266877167224885
36,139930,176,0.8684,0.35506734631061554
37,204325,257,0.8692,0.3637351914644241
38,170140,214,0.871,0.3630762129545212
39,192400,242,0.8696,0.3523658376932144
40,229765,289,0.8761,0.34436205734014513
41,201145,253,0.8819,0.3341322140932083
42,259975,327,0.8699,0.3584679736018181
43,307675,387,0.8731,0.3472274311304092
44,327550,412,0.8614,0.37217608728408813
45,351400,442,0.8658,0.3597690988898277
46,183655,231,0.8791,0.34703968398571017
47,182860,230,0.8795,0.33757048530578615
48,164575,207,0.8761,0.34015614899396895
49,157420,198,0.8757,0.34256260715723036
50,169345,213,0.8777,0.34255896604061126
51,207505,261,0.8657,0.38259022005796434
52,207505,261,0.8789,0.3401011778593063
53,189220,238,0.8766,0.3452273607730865
54,186040,234,0.8778,0.35305510711669924
55,199555,251,0.8797,0.3418074275970459
56,222610,280,0.8766,0.34671742490530016
57,137545,173,0.8613,0.37319622980356215
58,193195,243,0.8738,0.3479654510974884
59,218635,275,0.8706,0.36930004556179047
60,218635,275,0.8772,0.3416082612872124
61,292570,368,0.8801,0.33052823296785355
62,120850,152,0.8749,0.342683456325531
63,188425,237,0.8785,0.33817215883731844
64,137545,173,0.8761,0.34623274095058443
65,248845,313,0.8656,0.3728114186286926
66,237715,299,0.871,0.3608825601100922
67,283030,356,0.8767,0.34460187331438064
68,186835,235,0.8577,0.4059149400353432
69,221020,278,0.8811,0.33328046818971635
70,184450,232,0.8673,0.3887879172801971
71,201940,254,0.8735,0.35852895386219025
