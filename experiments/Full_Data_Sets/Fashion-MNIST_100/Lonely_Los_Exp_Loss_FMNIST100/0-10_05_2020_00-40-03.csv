Experiment 1 ,10_05_2020_00-40-03

Data shape and running
input_shape ,"(28, 28)"
output_shape ,10
scaling ,255.0
epochs ,5
max_runtime,10800
dataset_percentage,1.0
dataset,fashion_mnist

Hyper parameters
activation_function ,Activation.relu
initial_max_nodes ,50
loss_function ,Loss.sparse_categorical_crossentropy
optimizer ,Optimizer.Adam

GA parameters
population_size ,10
mating_pool ,10
mutation_rate,0.8

OUTPUT
generation_no,params_no,neurons_no,accuracy,loss
0,28630,36,0.8629,0.3758222666740417
1,38170,48,0.8512,0.4010872828960419
2,33400,42,0.8646,0.37896061010360715
3,33400,42,0.8475,0.4080034574270248
4,38170,48,0.8698,0.3676770245075226
5,44530,56,0.8722,0.35292975487709044
6,36580,46,0.8644,0.36711737480163575
7,46120,58,0.8706,0.3574400734424591
8,41350,52,0.8714,0.36137466039657595
9,50095,63,0.8733,0.3517025408744812
10,50095,63,0.8641,0.37744353309869766
11,54070,68,0.8764,0.3462209118366241
12,60430,76,0.8663,0.3664676046848297
13,73945,93,0.8694,0.3580514532327652
14,81100,102,0.8703,0.3571278841018677
15,73150,92,0.8731,0.36260688159465787
16,93820,118,0.8764,0.34674047875404357
17,105745,133,0.8656,0.35580713406801223
18,91435,115,0.8744,0.3563874711036682
19,108925,137,0.87,0.37107506484985353
20,112900,142,0.8707,0.3582694447398186
21,145495,183,0.8762,0.3409094715356827
22,101770,128,0.8786,0.3388798139691353
23,92230,116,0.8742,0.348386485350132
24,100180,126,0.8694,0.35289992972612383
25,67585,85,0.8752,0.36022180638313295
26,55660,70,0.8751,0.3529528680205345
27,57250,72,0.8754,0.35073466222286226
28,70765,89,0.8689,0.36659249300956726
29,64405,81,0.868,0.3589283860206604
30,54865,69,0.8668,0.3591387705564499
31,59635,75,0.8697,0.3577705363512039
32,62020,78,0.8588,0.39985636041164396
33,70765,89,0.8739,0.35591505718231203
34,89050,112,0.8685,0.35672761163711547
35,108130,136,0.8794,0.3280461563229561
36,87460,110,0.8724,0.3554919796705246
37,97000,122,0.8718,0.3545166579008102
38,88255,111,0.8779,0.34575143362283706
39,93820,118,0.8756,0.3546590274810791
40,116875,147,0.8748,0.34422107092142107
41,116875,147,0.8747,0.33814459862709045
42,101770,128,0.8643,0.3690756418466568
43,81100,102,0.8694,0.3732526474475861
44,81100,102,0.8644,0.376491678071022
45,77125,97,0.8734,0.3525859261274338
46,60430,76,0.8669,0.36814538350105286
47,61225,77,0.8741,0.34993361315727234
48,73945,93,0.8687,0.36273839178085326
49,60430,76,0.8737,0.3524698579788208
50,57250,72,0.8676,0.37282532958984377
51,65995,83,0.8645,0.36979284720420835
52,69970,88,0.8718,0.3626606634378433
53,81895,103,0.8764,0.3406260907173157
54,91435,115,0.8685,0.3631980974674225
55,95410,120,0.8636,0.3651255417585373
56,106540,134,0.8795,0.3372423398017883
57,140725,177,0.8757,0.34154943306446073
58,178885,225,0.875,0.347263973069191
59,185245,233,0.8742,0.35313128041028974
60,160600,202,0.8657,0.37181133918762205
61,190810,240,0.8764,0.34117686655521395
62,190810,240,0.8753,0.3449590729236603
63,239305,301,0.874,0.35307154264450075
64,226585,285,0.8748,0.3475099287033081
65,182065,229,0.8745,0.3581744197368622
66,182065,229,0.8618,0.3672787626504898
67,231355,291,0.8799,0.3327104861021042
68,267925,337,0.8732,0.349571706867218
69,268720,338,0.8776,0.33846790883541106
70,231355,291,0.8784,0.33493004027605056
