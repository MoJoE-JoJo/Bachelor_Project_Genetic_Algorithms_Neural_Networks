Experiment 3 ,09_03_2020_07-07-54

Data shape and running
input_shape ,"(28, 28)"
output_shape ,10
scaling ,255.0
epochs ,5
max_runtime,1800
dataset_percentage,0.1
dataset,mnist

Hyper parameters
activation_function ,Activation.relu
initial_max_nodes ,50
loss_function ,Loss.sparse_categorical_crossentropy
optimizer ,Optimizer.Adam

GA parameters
population_size ,10
mating_pool ,10
mutation_rate,0.2

OUTPUT
generation_no,params_no,neurons_no,accuracy,loss
0,3985,5,0.792,0.6618776903152466
1,3190,4,0.764,0.7786974754333497
2,3190,4,0.759,0.7587250270843506
3,3190,4,0.717,0.8243810043334961
4,2395,3,0.693,1.1641792621612548
5,2395,3,0.621,1.1265919694900512
6,2395,3,0.63,1.2282760620117188
7,1600,2,0.488,1.5517283439636231
8,1600,2,0.422,1.6490020542144774
9,805,1,0.253,1.9749390716552735
10,50890,64,0.916,0.27010364151000976
11,46120,58,0.91,0.28848283886909487
12,38965,49,0.904,0.2934748818874359
13,30220,38,0.89,0.35571506452560425
14,27040,34,0.912,0.31144173645973205
15,25450,32,0.906,0.31518753814697265
16,27835,35,0.906,0.30780017709732055
17,32605,41,0.893,0.33371616768836976
18,28630,36,0.904,0.2956516797542572
19,24655,31,0.905,0.3151422908306122
20,28630,36,0.905,0.3165785264968872
21,27835,35,0.908,0.2892849624156952
22,27835,35,0.902,0.3069688611030579
23,26245,33,0.909,0.30250560665130616
24,27835,35,0.9,0.3286453347206116
25,22270,28,0.895,0.3334537534713745
26,18295,23,0.898,0.3372151107788086
27,14320,18,0.895,0.3524990863800049
28,15115,19,0.897,0.3422656908035278
29,14320,18,0.895,0.34654133987426755
30,12730,16,0.886,0.37165974473953245
31,10345,13,0.877,0.3887432379722595
32,9550,12,0.875,0.3967917532920837
33,7165,9,0.866,0.4668166227340698
34,6370,8,0.862,0.4531707935333252
35,5575,7,0.831,0.5461344966888427
36,3985,5,0.766,0.6823574571609498
37,3190,4,0.708,0.899198477268219
38,2395,3,0.626,1.2197152576446533
39,2395,3,0.639,1.2083091449737549
40,2395,3,0.572,1.255865930557251
41,2395,3,0.655,1.1635830783843994
42,7165,9,0.856,0.46042394828796385
43,2395,3,0.591,1.1610146656036378
44,7960,10,0.875,0.416182163476944
45,11935,15,0.894,0.363231593132019
46,1600,2,0.472,1.5493775119781494
47,10345,13,0.893,0.3907864956855774
48,11140,14,0.893,0.3682360053062439
49,10345,13,0.889,0.3607400555610657
50,10345,13,0.876,0.37729912996292114
51,9550,12,0.876,0.4223075737953186
52,7960,10,0.867,0.42305626916885375
53,7165,9,0.883,0.42715901517868043
54,5575,7,0.864,0.4798952670097351
55,5575,7,0.863,0.4964051284790039
56,3985,5,0.798,0.8192721982002258
57,3985,5,0.794,0.6919401454925537
58,5575,7,0.857,0.4964772710800171
59,3985,5,0.801,0.6904826288223267
60,4780,6,0.838,0.6060590019226074
61,4780,6,0.817,0.5965132098197937
62,3985,5,0.777,0.7917489776611328
63,3985,5,0.782,0.6943126952648163
64,3985,5,0.791,0.7043175678253174
65,3190,4,0.731,0.8740221281051636
66,3985,5,0.82,0.6406313285827637
67,3190,4,0.736,0.9070407762527466
68,3190,4,0.734,0.8901499481201172
69,3985,5,0.801,0.7076671543121338
70,3985,5,0.829,0.6378134412765503
71,3985,5,0.776,0.7080020818710328
72,2395,3,0.653,1.221596381187439
73,3985,5,0.812,0.611182580947876
74,3985,5,0.818,0.6002758569717407
75,3190,4,0.711,0.9270591049194336
76,3985,5,0.805,0.6678291893005371
77,2395,3,0.68,1.1310777473449707
78,3985,5,0.809,0.6571140656471253
79,3190,4,0.707,0.9634008121490478
80,3190,4,0.716,0.9269814701080322
81,3985,5,0.831,0.5969599757194519
82,3985,5,0.77,0.7586004238128662
83,3985,5,0.79,0.6766366491317749
84,3985,5,0.796,0.7167900171279907
85,3985,5,0.786,0.693249228477478
86,3985,5,0.754,0.7628598527908326
87,3985,5,0.802,0.6657102313041687
88,4780,6,0.808,0.5981426057815552
89,3190,4,0.755,0.76246475315094
90,4780,6,0.85,0.5308193855285644
91,3190,4,0.746,0.8322860069274902
92,3190,4,0.729,0.9453487162590026
