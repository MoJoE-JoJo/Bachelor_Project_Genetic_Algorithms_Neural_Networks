Experiment 3 ,28_04_2020_05-02-49

Data shape and running
input_shape ,"(28, 28)"
output_shape ,10
scaling ,255.0
epochs ,5
max_runtime,10800
dataset_percentage,1.0
dataset,mnist

Hyper parameters
activation_function ,Activation.relu
initial_max_nodes ,50
loss_function ,Loss.sparse_categorical_crossentropy
optimizer ,Optimizer.Adam

GA parameters
population_size ,10
mating_pool ,10
mutation_rate,0.8

OUTPUT
generation_no,params_no,neurons_no,accuracy,loss
0,38170,48,0.9709,0.09380920233847573
1,34990,44,0.9665,0.11114410721156746
2,42940,54,0.9687,0.10168533715978265
3,54865,69,0.9726,0.09011818245281465
4,54865,69,0.9716,0.08791233251802623
5,61225,77,0.9758,0.08486899855574592
6,62020,78,0.9713,0.09417061201054602
7,69175,87,0.9744,0.08724107793485746
8,69175,87,0.9744,0.08515110727329739
9,76330,96,0.9757,0.08107267049844377
10,76330,96,0.9752,0.07895029795207083
11,62815,79,0.9739,0.08170388564979658
12,64405,81,0.9745,0.08428100331197493
13,63610,80,0.9743,0.08337628474375233
14,78715,99,0.9742,0.08484429160673171
15,94615,119,0.9777,0.07726132619660347
16,118465,149,0.9785,0.07425665039439919
17,116080,146,0.9768,0.07113151535424404
18,142315,179,0.9796,0.0649333962540375
19,178885,225,0.98,0.07074554891710869
20,205915,259,0.9762,0.07384775984890293
21,256000,322,0.9722,0.09133497425079112
22,256000,322,0.9802,0.06365041527131107
23,256000,322,0.9793,0.06928960221562301
24,273490,344,0.9792,0.0752616607901291
25,256795,323,0.977,0.07546137073779828
26,321190,404,0.9783,0.06521668394532754
27,302905,381,0.9808,0.06409385945440736
28,339475,427,0.9771,0.07882333935964271
29,401485,505,0.9809,0.0668815289643535
30,405460,510,0.9806,0.06993260898404405
31,575590,724,0.9807,0.06842602070110151
32,582745,733,0.9805,0.06887020444730296
33,608185,765,0.977,0.07560661947032205
34,469855,591,0.981,0.06508324369287584
35,362530,456,0.9805,0.066439483125275
36,465880,586,0.9783,0.07051223432244151
37,450775,567,0.9777,0.07505067730010778
38,422950,532,0.9742,0.08950845032283104
39,657475,827,0.9806,0.06535468645407527
40,741745,933,0.9774,0.08430514504278254
41,938110,1180,0.9806,0.07312901701111259
42,513580,646,0.9783,0.07357903335586306
43,396715,499,0.9799,0.06864536006820854
44,657475,827,0.9789,0.07095550679790903
45,441235,555,0.9748,0.0901100293269963
46,580360,730,0.9788,0.07993458284424851
47,964345,1213,0.9792,0.07523284180155461
48,488140,614,0.9765,0.0793386025606771
49,527095,663,0.9797,0.0726544303908071
50,764005,961,0.9797,0.0741729636552569
51,786265,989,0.9826,0.07067315565524623
52,1042255,1311,0.9791,0.07539704988829325
53,624880,786,0.9794,0.07867318019728409
54,659860,830,0.9803,0.06748086484214873
55,486550,612,0.9811,0.06488435082400393
56,387970,488,0.9806,0.06721340946502169
57,487345,613,0.979,0.07723560617170878
58,648730,816,0.9804,0.07320087733843829
59,648730,816,0.9812,0.06892791404706368
60,748900,942,0.9818,0.06079648761662538
61,484165,609,0.9774,0.08012842652920808
62,548560,690,0.9811,0.06364201320091961
63,656680,826,0.9794,0.07400274119319801
64,656680,826,0.9797,0.07338404904604831
65,764005,961,0.9793,0.06645212730892526
