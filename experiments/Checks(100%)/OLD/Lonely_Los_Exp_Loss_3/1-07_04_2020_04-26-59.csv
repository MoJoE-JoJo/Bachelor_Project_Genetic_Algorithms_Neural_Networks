Experiment 2 ,07_04_2020_04-26-59

Data shape and running
input_shape ,"(28, 28)"
output_shape ,10
scaling ,255.0
epochs ,5
max_runtime,10800
dataset_percentage,1.0
dataset,mnist

Hyper parameters
activation_function ,Activation.relu
initial_max_nodes ,50
loss_function ,Loss.sparse_categorical_crossentropy
optimizer ,Optimizer.Adam

GA parameters
population_size ,10
mating_pool ,10
mutation_rate,0.8

OUTPUT
generation_no,params_no,neurons_no,accuracy,loss
0,30220,38,0.9678,0.10581091463193297
1,40555,51,0.9713,0.09108547840397804
2,49300,62,0.9729,0.09543833565376698
3,49300,62,0.9709,0.09232630948852748
4,49300,62,0.9742,0.09049134597266092
5,49300,62,0.9709,0.09484634861601517
6,49300,62,0.9717,0.09585478795450181
7,60430,76,0.9761,0.07937141791898757
8,60430,76,0.9749,0.08328825348960235
9,71560,90,0.9765,0.07670467731077224
10,73945,93,0.9752,0.08465917839235626
11,102565,129,0.977,0.0792804514428135
12,92230,116,0.9768,0.07262669274243526
13,102565,129,0.9772,0.07085251538073645
14,88255,111,0.9779,0.08105413437690585
15,97000,122,0.9756,0.07522018512350041
16,112900,142,0.9772,0.07143757350896485
17,102565,129,0.9766,0.07512171665149509
18,144700,182,0.9778,0.07331478192936629
19,144700,182,0.9775,0.07543757914388552
20,169345,213,0.978,0.07113961631124839
21,215455,271,0.9799,0.06912537110759877
22,252820,318,0.9784,0.07256051633274183
23,312445,393,0.9808,0.06909913138937554
24,259180,326,0.9737,0.08543736111702165
25,275875,347,0.9789,0.06184855980296852
26,355375,447,0.9812,0.06488964304762485
27,443620,558,0.9769,0.08344540805249416
28,472240,594,0.977,0.081978141649178
29,299725,377,0.9825,0.06056746923251776
30,347425,437,0.9784,0.07383520711392338
31,337090,424,0.981,0.06381261796791805
32,310855,391,0.9792,0.07213968003803747
33,336295,423,0.9796,0.07024846171767277
34,387175,487,0.9811,0.07053155595451244
35,293365,369,0.9794,0.07302848756453605
36,387175,487,0.9779,0.07455266037869442
37,412615,519,0.9791,0.07205818349499604
38,331525,417,0.9813,0.06218736561409314
39,534250,672,0.9793,0.07135707489411579
40,392740,494,0.9812,0.06443115395120694
41,331525,417,0.9778,0.07041305367288878
42,577975,727,0.9764,0.08306198735916114
43,691660,870,0.982,0.06866812882283557
44,388765,489,0.9798,0.06993617534039367
45,501655,631,0.9808,0.0664286815994361
46,483370,608,0.9797,0.07303079466425552
47,552535,695,0.9789,0.07871430970569782
48,446005,561,0.9766,0.0792002194616769
49,750490,944,0.9791,0.06915956140471971
50,473830,596,0.9761,0.07870070162799093
51,555715,699,0.9777,0.0757236439642962
52,395125,497,0.9772,0.07645829752096907
53,395125,497,0.9768,0.07867794316908112
54,356170,448,0.978,0.07325973271546536
55,458725,577,0.9781,0.07354550490865368
56,480985,605,0.9797,0.0721503393096733
57,796600,1002,0.9798,0.07228933776572084
58,408640,514,0.9814,0.06195564227840514
59,492115,619,0.9778,0.07663501850795292
60,616930,776,0.9803,0.06781766429431155
61,442030,556,0.978,0.07306828627123031
62,552535,695,0.9762,0.08563253110743244
63,628855,791,0.9766,0.07753842426831543
64,591490,744,0.9752,0.09156590678580105
65,586720,738,0.9755,0.09235582841105207
66,380020,478,0.9793,0.06960796081271256
67,576385,725,0.9779,0.07935559359818872
68,520735,655,0.9765,0.07945018259034259
69,520735,655,0.9782,0.077981709844945
70,721075,907,0.9795,0.06906768681662652
71,659065,829,0.9787,0.0695180468940438
72,519145,653,0.9813,0.06497409416462033
73,588310,740,0.9769,0.09202999545807543
