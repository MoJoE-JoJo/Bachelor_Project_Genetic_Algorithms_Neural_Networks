Experiment 3 ,07_04_2020_07-26-59

Data shape and running
input_shape ,"(28, 28)"
output_shape ,10
scaling ,255.0
epochs ,5
max_runtime,10800
dataset_percentage,1.0
dataset,mnist

Hyper parameters
activation_function ,Activation.relu
initial_max_nodes ,50
loss_function ,Loss.sparse_categorical_crossentropy
optimizer ,Optimizer.Adam

GA parameters
population_size ,10
mating_pool ,10
mutation_rate,0.8

OUTPUT
generation_no,params_no,neurons_no,accuracy,loss
0,39760,50,0.9711,0.10100429732846096
1,50890,64,0.9727,0.08580944067826494
2,41350,52,0.9713,0.09313485960597172
3,50890,64,0.9715,0.08957466700868681
4,41350,52,0.9721,0.0970220356034115
5,38965,49,0.9712,0.09503789583481848
6,50890,64,0.9721,0.09355851971490774
7,51685,65,0.9697,0.09723854034654796
8,61225,77,0.9741,0.0880529568266822
9,68380,86,0.9755,0.07828202970577404
10,86665,109,0.9762,0.07629901609627995
11,86665,109,0.9738,0.08409980075135827
12,86665,109,0.9768,0.07612153301469517
13,86665,109,0.9752,0.07627322849207557
14,95410,120,0.977,0.07588829890643246
15,119260,150,0.9783,0.06624489761199802
16,154240,194,0.9809,0.06707546262925025
17,135160,170,0.9761,0.0790122295078123
18,119260,150,0.9789,0.0712029742105864
19,171730,216,0.978,0.07134641156043509
20,177295,223,0.9794,0.06865281778589123
21,196375,247,0.98,0.06676605099411681
22,234535,295,0.9807,0.06549819175797747
23,218635,275,0.9804,0.06875781242470257
24,225790,284,0.9755,0.0827934127535671
25,273490,344,0.9789,0.07015190224181861
26,198760,250,0.9787,0.06852842413094477
27,190810,240,0.9762,0.0803521879611304
28,221815,279,0.9805,0.06985540208990569
29,262360,330,0.9813,0.06349468375011347
30,314035,395,0.9785,0.07199940203733277
31,382405,481,0.9803,0.06945396353065153
32,442030,556,0.9819,0.06561659570081392
33,312445,393,0.9771,0.07551207426406908
34,363325,457,0.9799,0.0773658850471984
35,335500,422,0.982,0.06384015363473446
36,407845,513,0.9785,0.07725108130077715
37,469060,590,0.9841,0.058469420712359714
38,399895,503,0.9768,0.08169204158944776
39,715510,900,0.9801,0.06625945373465074
40,474625,597,0.9832,0.06106503644664772
41,474625,597,0.9766,0.08276662810693379
42,473830,596,0.9801,0.06572098506441107
43,415795,523,0.9768,0.0850943348999077
44,430105,541,0.9824,0.06440159136541188
45,290980,366,0.9773,0.07224150625529001
46,418180,526,0.9801,0.06662345207111793
47,301315,379,0.9784,0.07125472409403882
48,693250,872,0.9746,0.09024772647746432
49,384790,484,0.9807,0.06671492486779462
50,323575,407,0.9793,0.06730853204389568
51,811705,1021,0.9813,0.06777962138600414
52,590695,743,0.982,0.058607344219306835
53,672580,846,0.9801,0.06879062259448256
54,404665,509,0.9808,0.0706260511509201
55,616135,775,0.977,0.08496328066214046
56,482575,607,0.9803,0.06939802963074762
57,728230,916,0.9803,0.07190963906656252
58,804550,1012,0.9772,0.07986876084849936
59,441235,555,0.9781,0.0747891355216474
60,530275,667,0.9835,0.06099759633730864
61,530275,667,0.9793,0.07318734019765398
62,622495,783,0.9746,0.08997886665426194
63,424540,534,0.9795,0.06811335828246665
64,424540,534,0.9774,0.0780282863894201
65,448390,564,0.9784,0.07196265654298185
66,469855,591,0.9734,0.08719518187494832
67,358555,451,0.9765,0.08105710816609207
68,614545,773,0.9778,0.08799771993951871
69,608980,766,0.9805,0.06660342896068178
70,539020,678,0.9816,0.06222564134780841
71,774340,974,0.9813,0.06542964373161812
72,730615,919,0.9799,0.07749136117412418
