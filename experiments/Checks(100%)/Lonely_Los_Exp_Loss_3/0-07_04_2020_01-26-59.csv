Experiment 1 ,07_04_2020_01-26-59

Data shape and running
input_shape ,"(28, 28)"
output_shape ,10
scaling ,255.0
epochs ,5
max_runtime,10800
dataset_percentage,1.0
dataset,mnist

Hyper parameters
activation_function ,Activation.relu
initial_max_nodes ,50
loss_function ,Loss.sparse_categorical_crossentropy
optimizer ,Optimizer.Adam

GA parameters
population_size ,10
mating_pool ,10
mutation_rate,0.8

OUTPUT
generation_no,params_no,neurons_no,accuracy,loss
0,37375,47,0.9679,0.10430893227532506
1,45325,57,0.9703,0.09501212422400714
2,54070,68,0.9759,0.08399343829089775
3,69175,87,0.9742,0.08678725261047948
4,73945,93,0.9771,0.08053953406857327
5,63610,80,0.9711,0.09635905827274546
6,81100,102,0.9768,0.07906504978314043
7,104950,132,0.977,0.07323137550810352
8,123235,155,0.9769,0.07222877869687509
9,124030,156,0.9782,0.06902712680883706
10,136750,172,0.9774,0.07607695765721147
11,150265,189,0.9778,0.07315578194244299
12,167755,211,0.9783,0.06700513053059112
13,209095,263,0.9773,0.07006896561251487
14,230560,290,0.9779,0.07260843829948571
15,196375,247,0.9773,0.06959562213283498
16,251230,316,0.9808,0.06566642442294396
17,251230,316,0.9807,0.06246267075317446
18,302905,381,0.978,0.0741095964500273
19,351400,442,0.9799,0.06700018509470392
20,442825,557,0.9771,0.0802908606079407
21,403870,508,0.9817,0.0668446212591749
22,409435,515,0.9797,0.06812539303230587
23,417385,525,0.9823,0.06584462695725088
24,462700,582,0.9768,0.07735552617784124
25,438850,552,0.9754,0.08359783265118022
26,519145,653,0.9837,0.05781787647231977
27,697225,877,0.9758,0.08246817728094756
28,528685,665,0.9776,0.07518786530186189
29,599440,754,0.9785,0.072382574889221
30,550150,692,0.9796,0.07522687364659505
31,574000,722,0.9798,0.07232884807501978
32,531070,668,0.9794,0.07293643859396107
33,546175,687,0.9781,0.07448320176753914
34,439645,553,0.9788,0.07367165547682089
35,476215,599,0.9758,0.08325113781818655
36,569230,716,0.9798,0.07905831887607637
37,533455,671,0.9801,0.06871156044699601
38,508810,640,0.9792,0.07074211098161176
39,507220,638,0.9785,0.07712532741618343
40,909490,1144,0.9809,0.06755906724064553
41,446005,561,0.9807,0.06416528267925314
42,689275,867,0.9801,0.06356753894129069
43,592285,745,0.9802,0.07043171900243032
44,495295,623,0.9802,0.07231712937193516
45,407050,512,0.978,0.07392004946315428
46,574000,722,0.9815,0.06810126914654684
47,400690,504,0.981,0.07022728954712511
48,401485,505,0.9818,0.059644376229133926
49,742540,934,0.9804,0.07179789166538394
50,344245,433,0.9813,0.06446038327733404
51,677350,852,0.9798,0.07135435763083514
52,403870,508,0.9805,0.0641747419506195
53,1047820,1318,0.9798,0.0754468450217857
54,471445,593,0.9806,0.0678626665692369
55,565255,711,0.9803,0.06789915395510616
56,469060,590,0.9787,0.06850022616357601
57,477010,600,0.9771,0.08081356555295642
58,798985,1005,0.9777,0.08368132747806521
59,702790,884,0.9802,0.06615211013839871
60,624880,786,0.9807,0.07407142022597836
61,758440,954,0.9753,0.0887387342442904
62,620905,781,0.9807,0.06886085509149853
63,528685,665,0.9752,0.0804236293170543
64,600235,755,0.9811,0.06813162550366542
65,492115,619,0.9805,0.06900277257438284
66,564460,710,0.9805,0.06688586670290679
67,598645,753,0.9775,0.07911509335491573
68,727435,915,0.9823,0.06975828909835181
69,632830,796,0.9774,0.07899189836447476
70,768775,967,0.9791,0.07427180452570319
71,779110,980,0.9805,0.07307748321601248
72,756055,951,0.9824,0.06691257140635862
