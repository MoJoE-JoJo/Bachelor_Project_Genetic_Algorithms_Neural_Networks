Experiment 1 ,08_03_2020_13-58-56

Data shape and running
input_shape ,"(28, 28)"
output_shape ,10
scaling ,255.0
epochs ,5
max_runtime,1800
dataset_percentage,0.1
dataset,mnist

Hyper parameters
activation_function ,Activation.relu
initial_max_nodes ,50
loss_function ,Loss.sparse_categorical_crossentropy
optimizer ,Optimizer.Adam

GA parameters
population_size ,10
mating_pool ,10
mutation_rate,0.2

OUTPUT
generation_no,params_no,neurons_no,accuracy,loss
0,27040,34,0.904,0.3107531280517578
1,42940,54,0.908,0.2952620232105255
2,26245,33,0.91,0.2996068811416626
3,16705,21,0.903,0.327091073513031
4,24655,31,0.89,0.33417472124099734
5,30220,38,0.892,0.3225599715709686
6,28630,36,0.908,0.2891291172504425
7,19885,25,0.899,0.32350303173065187
8,47710,60,0.912,0.27343011951446533
9,33400,42,0.898,0.3010822491645813
10,13525,17,0.879,0.3678103289604187
11,44530,56,0.911,0.27781726694107056
12,44530,56,0.913,0.27362850975990294
13,54865,69,0.91,0.26924161648750305
14,29425,37,0.902,0.31532697343826294
15,11935,15,0.885,0.36259927082061766
16,10345,13,0.887,0.3746219172477722
17,38170,48,0.905,0.3026318039894104
18,38170,48,0.911,0.2822128598690033
19,22270,28,0.895,0.3341070809364319
20,10345,13,0.889,0.35996427631378175
21,50095,63,0.901,0.2891145534515381
22,62815,79,0.919,0.26853410840034486
23,24655,31,0.895,0.3184988107681274
24,29425,37,0.905,0.3052253143787384
25,62020,78,0.912,0.25804897713661196
26,62020,78,0.917,0.27593761777877807
27,77920,98,0.921,0.2479738699197769
28,65995,83,0.914,0.2600412013530731
29,38170,48,0.905,0.29911580085754397
30,52480,66,0.907,0.2710057890415192
31,59635,75,0.918,0.26282415008544924
32,58840,74,0.914,0.26711181354522706
33,50890,64,0.915,0.2874221284389496
34,61225,77,0.907,0.2756743929386139
35,57250,72,0.914,0.27103909468650816
36,50095,63,0.909,0.28088562965393066
37,57250,72,0.916,0.2814205635786057
38,53275,67,0.914,0.27618087887763976
39,38965,49,0.911,0.2971189739704132
40,69175,87,0.914,0.2513121812343597
41,85075,107,0.918,0.25634995198249816
42,99385,125,0.923,0.2504450707435608
43,122440,154,0.922,0.23340175032615662
44,145495,183,0.929,0.23005883657932283
45,128800,162,0.919,0.23557812786102295
46,147085,185,0.925,0.22773274338245392
47,155035,195,0.919,0.24453532981872558
48,152650,192,0.923,0.24279315733909607
49,152650,192,0.922,0.23683799624443055
50,185245,233,0.931,0.2251946622133255
51,153445,193,0.928,0.2177706160545349
52,227380,286,0.934,0.21852334427833559
53,289390,364,0.931,0.19882701587677
54,225790,284,0.924,0.2338208246231079
55,289390,364,0.935,0.1897501105070114
56,290185,365,0.93,0.20844448268413543
57,267130,336,0.928,0.21591154599189757
58,291775,367,0.928,0.21951218295097352
59,317215,399,0.937,0.19056767749786377
60,341860,430,0.933,0.21510123133659362
61,330730,416,0.934,0.19095578980445863
62,364915,459,0.917,0.24442855072021485
63,313240,394,0.927,0.20116986000537873
64,419770,528,0.935,0.2001675658226013
65,430900,542,0.928,0.20812570932507515
66,404665,509,0.933,0.20854280161857605
67,454750,572,0.935,0.19600172877311706
68,615340,774,0.94,0.1717372288107872
69,516760,650,0.939,0.19731471133232117
70,642370,808,0.94,0.18831463170051574
71,437260,550,0.932,0.18809808260202407
72,474625,597,0.932,0.2059757524728775
73,558895,703,0.923,0.21080613219738006
74,682120,858,0.943,0.17936210614442824
75,844300,1062,0.939,0.18183651280403137
76,844300,1062,0.942,0.21759342575073243
77,814090,1024,0.941,0.18223840469121932
78,963550,1212,0.942,0.18170887207984923
79,1093135,1375,0.93,0.21004952973127364
80,1123345,1413,0.926,0.21414430773258208
81,1177405,1481,0.937,0.1940059717297554
82,917440,1154,0.934,0.19145913782715798
83,1344355,1691,0.938,0.18624103802442551
