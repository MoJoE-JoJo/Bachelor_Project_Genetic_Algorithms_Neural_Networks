Experiment 1 ,12_03_2020_00-45-05

Data shape and running
input_shape ,"(28, 28)"
output_shape ,10
scaling ,255.0
epochs ,5
max_runtime,1800
dataset_percentage,0.1
dataset,mnist

Hyper parameters
activation_function ,Activation.selu
initial_max_nodes ,50
loss_function ,Loss.sparse_categorical_crossentropy
optimizer ,Optimizer.Adam

GA parameters
population_size ,10
mating_pool ,10
mutation_rate,0.2

OUTPUT
generation_no,params_no,neurons_no,accuracy,loss
0,34195,43,0.899,0.3289152328968048
1,42145,53,0.899,0.33119538974761964
2,38170,48,0.89,0.35594519758224485
3,38965,49,0.896,0.3484628949165344
4,45325,57,0.905,0.3182138810157776
5,40555,51,0.901,0.3178925921916962
6,58045,73,0.896,0.32425874018669126
7,62815,79,0.893,0.33682335567474364
8,42940,54,0.899,0.32985214805603025
9,82690,104,0.896,0.3412262191772461
10,72355,91,0.887,0.36540103697776793
11,100975,127,0.893,0.34574572658538816
12,77125,97,0.907,0.3067989420890808
13,135160,170,0.893,0.3331068296432495
14,174115,219,0.904,0.3389710495471954
15,178090,224,0.9,0.3533399486541748
16,205915,259,0.888,0.357031548500061
17,227380,286,0.889,0.35082852411270143
18,246460,310,0.902,0.3415063190460205
19,240895,303,0.885,0.3847027990818024
20,318010,400,0.898,0.34160373425483703
21,205120,258,0.888,0.38031791615486144
22,233740,294,0.896,0.34282629370689394
23,162190,204,0.892,0.3532364485263825
24,248845,313,0.9,0.3404653072357178
25,232150,292,0.898,0.3376857657432556
26,192400,242,0.888,0.3565616676807404
27,196375,247,0.891,0.3577603445053101
28,218635,275,0.891,0.35626984405517576
29,271900,342,0.901,0.3521151809692383
30,276670,348,0.881,0.38546562993526456
31,254410,320,0.894,0.35178000235557555
32,316420,398,0.893,0.3800382785797119
33,318010,400,0.872,0.42163806772232054
34,461110,580,0.895,0.3732009606361389
35,548560,690,0.892,0.38690645241737365
36,466675,587,0.881,0.38409229564666747
37,457135,575,0.889,0.3813114323616028
38,422950,532,0.893,0.3757108585834503
39,278260,350,0.898,0.3570936359167099
40,401485,505,0.889,0.3795565757751465
41,372865,469,0.9,0.3637340018749237
42,434080,546,0.897,0.3817912909984589
43,448390,564,0.898,0.3517668294906616
44,485755,611,0.887,0.3986471803188324
45,536635,675,0.865,0.4521926128864288
46,520735,655,0.886,0.4200921413898468
47,586720,738,0.883,0.42549245023727417
48,570820,718,0.874,0.4738612174987793
49,463495,583,0.88,0.3971923611164093
50,417385,525,0.9,0.3622721426486969
51,519145,653,0.883,0.41115340662002564
52,535045,673,0.9,0.3683053405284882
53,541405,681,0.892,0.38182263135910033
54,501655,631,0.879,0.396641074180603
55,484960,610,0.883,0.41831352043151854
56,400690,504,0.888,0.37901949977874755
57,450775,567,0.881,0.4221207330226898
58,534250,672,0.905,0.36897193098068237
59,492910,620,0.893,0.38481968426704405
60,489730,616,0.879,0.395983747959137
61,673375,847,0.89,0.4089473638534546
62,647935,815,0.876,0.45201003551483154
63,489730,616,0.881,0.397227858543396
64,558895,703,0.891,0.3676228926181793
65,412615,519,0.886,0.38977887296676633
66,412615,519,0.903,0.35346435952186583
67,626470,788,0.883,0.4068022832870483
68,626470,788,0.883,0.40834048748016355
69,636010,800,0.897,0.37794229114055633
70,528685,665,0.893,0.3664556310176849
71,580360,730,0.893,0.36569201374053956
72,764800,962,0.884,0.44349800419807434
73,880870,1108,0.885,0.3936193971633911
74,948445,1193,0.897,0.36977992570400237
75,593080,746,0.883,0.4004794526100159
76,692455,871,0.882,0.4371783390045166
77,641575,807,0.884,0.4015273201465607
78,460315,579,0.894,0.3616901259422302
79,418975,527,0.894,0.39526714849472044
80,442030,556,0.895,0.3530544672012329
81,398305,501,0.883,0.3881291494369507
82,434080,546,0.893,0.3617456431388855
83,327550,412,0.888,0.37653105282783506
84,352195,443,0.888,0.3727285828590393
