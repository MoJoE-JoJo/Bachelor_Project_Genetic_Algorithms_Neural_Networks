Experiment 2 ,12_03_2020_01-15-05

Data shape and running
input_shape ,"(28, 28)"
output_shape ,10
scaling ,255.0
epochs ,5
max_runtime,1800
dataset_percentage,0.1
dataset,mnist

Hyper parameters
activation_function ,Activation.selu
initial_max_nodes ,50
loss_function ,Loss.sparse_categorical_crossentropy
optimizer ,Optimizer.Adam

GA parameters
population_size ,10
mating_pool ,10
mutation_rate,0.2

OUTPUT
generation_no,params_no,neurons_no,accuracy,loss
0,31015,39,0.9,0.3280230975151062
1,27040,34,0.902,0.33998571944236755
2,31810,40,0.888,0.33422018575668333
3,31810,40,0.899,0.32443287324905395
4,31810,40,0.896,0.3406242201328278
5,24655,31,0.881,0.38765449571609495
6,17500,22,0.89,0.34725701522827146
7,18295,23,0.885,0.348514990568161
8,20680,26,0.889,0.3465028886795044
9,19090,24,0.892,0.3426836180686951
10,25450,32,0.899,0.3517912855148315
11,25450,32,0.883,0.35595836544036863
12,29425,37,0.896,0.3401225028038025
13,31810,40,0.896,0.34560007619857785
14,37375,47,0.895,0.33641161036491396
15,41350,52,0.899,0.3391627984046936
16,36580,46,0.891,0.3358273539543152
17,31015,39,0.896,0.34368764925003054
18,39760,50,0.899,0.33395192432403564
19,28630,36,0.888,0.3418350386619568
20,39760,50,0.896,0.33760902571678164
21,30220,38,0.906,0.33487515306472776
22,32605,41,0.898,0.33231499648094176
23,37375,47,0.896,0.3245391411781311
24,43735,55,0.893,0.3320688788890839
25,54070,68,0.897,0.33369338274002075
26,58045,73,0.9,0.32658147978782653
27,38965,49,0.893,0.3374037718772888
28,38965,49,0.899,0.3400130608081818
29,34990,44,0.893,0.34294733524322507
30,45325,57,0.898,0.33332815003395083
31,37375,47,0.896,0.3366051912307739
32,44530,56,0.896,0.3314293184280396
33,40555,51,0.899,0.3295869851112366
34,54070,68,0.894,0.3393616588115692
35,57250,72,0.904,0.3247142539024353
36,55660,70,0.9,0.32508326244354246
37,52480,66,0.898,0.33521686244010923
38,41350,52,0.897,0.32528851509094237
39,38170,48,0.899,0.31993221831321716
40,48505,61,0.896,0.3283272159099579
41,58045,73,0.898,0.3258844442367554
42,41350,52,0.898,0.3406394500732422
43,53275,67,0.904,0.31634594678878786
44,74740,94,0.895,0.3580187301635742
45,49300,62,0.898,0.3235384931564331
46,62815,79,0.901,0.3273768169879913
47,62815,79,0.896,0.32634260153770445
48,55660,70,0.895,0.3415633177757263
49,51685,65,0.894,0.32001060581207275
50,65995,83,0.899,0.3343820667266846
51,46120,58,0.884,0.3585585153102875
52,42145,53,0.907,0.32977602553367613
53,33400,42,0.9,0.3267742111682892
54,40555,51,0.903,0.31968089723587034
55,47710,60,0.897,0.32724440670013427
56,44530,56,0.902,0.31674712753295897
57,50095,63,0.894,0.33807542037963867
58,60430,76,0.893,0.3615502200126648
59,60430,76,0.892,0.3258408331871033
60,73150,92,0.902,0.33161239051818847
61,82690,104,0.897,0.3323413429260254
62,73945,93,0.905,0.31682401490211487
63,86665,109,0.906,0.33647880840301514
64,66790,84,0.888,0.34336612462997435
65,48505,61,0.892,0.3270294072628021
66,65200,82,0.903,0.3375285258293152
67,65200,82,0.891,0.33685373711586
68,23065,29,0.896,0.3401144504547119
69,20680,26,0.898,0.3258784718513489
70,19885,25,0.893,0.36845050716400146
71,32605,41,0.897,0.34021859979629515
72,28630,36,0.893,0.34359944295883177
73,23860,30,0.894,0.3433556599617004
74,21475,27,0.888,0.3396771333217621
75,21475,27,0.895,0.34562183713912964
76,22270,28,0.9,0.3448146786689758
77,22270,28,0.894,0.3546963219642639
78,33400,42,0.899,0.3327002305984497
79,26245,33,0.891,0.3391754665374756
80,33400,42,0.895,0.3370165917873383
81,42145,53,0.891,0.34725310587882996
82,28630,36,0.9,0.3578531823158264
83,35785,45,0.892,0.3324155883789062
84,38965,49,0.901,0.33548808336257935
85,32605,41,0.9,0.3306394739151001
86,36580,46,0.896,0.3447878346443176
87,34195,43,0.898,0.3415276675224304
88,20680,26,0.898,0.35066047620773316
89,19885,25,0.886,0.3553221502304077
90,17500,22,0.883,0.3624632601737976
