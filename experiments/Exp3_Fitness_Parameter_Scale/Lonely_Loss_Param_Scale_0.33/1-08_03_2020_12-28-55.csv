Experiment 2 ,08_03_2020_12-28-55

Data shape and running
input_shape ,"(28, 28)"
output_shape ,10
scaling ,255.0
epochs ,5
max_runtime,1800
dataset_percentage,0.1
dataset,mnist

Hyper parameters
activation_function ,Activation.relu
initial_max_nodes ,50
loss_function ,Loss.sparse_categorical_crossentropy
optimizer ,Optimizer.Adam

GA parameters
population_size ,10
mating_pool ,10
mutation_rate,0.2

OUTPUT
generation_no,params_no,neurons_no,accuracy,loss
0,8755,11,0.881,0.384320725440979
1,25450,32,0.908,0.3150257334709167
2,29425,37,0.914,0.2884595055580139
3,12730,16,0.898,0.35341095542907713
4,33400,42,0.902,0.29177005755901336
5,45325,57,0.905,0.2807438344955444
6,38170,48,0.906,0.28780952072143556
7,46120,58,0.914,0.28470457673072813
8,52480,66,0.91,0.28816354370117186
9,22270,28,0.892,0.314108154296875
10,21475,27,0.893,0.3208622119426727
11,58840,74,0.907,0.2676800122261047
12,41350,52,0.913,0.2701457691192627
13,54070,68,0.918,0.26921174001693726
14,41350,52,0.908,0.2958545424938202
15,50095,63,0.909,0.2718884880542755
16,43735,55,0.913,0.2649890366792679
17,81100,102,0.908,0.27006061124801634
18,67585,85,0.914,0.2667586076259613
19,81100,102,0.925,0.24065633034706116
20,73945,93,0.913,0.26010869693756106
21,81100,102,0.928,0.24789081931114196
22,81100,102,0.913,0.26247555255889893
23,90640,114,0.915,0.2554881920814514
24,88255,111,0.915,0.24445882678031922
25,107335,135,0.924,0.2356951971054077
26,112900,142,0.925,0.23617678451538085
27,158215,199,0.918,0.23674035120010375
28,96205,121,0.925,0.23568522357940674
29,100180,126,0.922,0.2321372569799423
30,177295,223,0.932,0.20688784074783326
31,149470,188,0.926,0.23318005514144896
32,166960,210,0.932,0.2132071727514267
33,141520,178,0.932,0.2133290958404541
34,155035,195,0.921,0.22646913540363312
35,157420,198,0.918,0.2215293023586273
36,175705,221,0.925,0.21755714392662048
37,175705,221,0.921,0.22474236238002776
38,205120,258,0.93,0.2082428823709488
39,259180,326,0.929,0.2143666546344757
40,295750,372,0.926,0.20948959350585938
41,325165,409,0.936,0.1962838476896286
42,392740,494,0.937,0.19931249290704728
43,253615,319,0.933,0.2097777419090271
44,263155,331,0.929,0.20160378634929657
45,209095,263,0.924,0.2228119376897812
46,221815,279,0.921,0.2164016163945198
47,195580,246,0.93,0.22267793810367584
48,236920,298,0.925,0.20901410460472106
49,290185,365,0.931,0.22076042461395265
50,211480,266,0.924,0.2149094455242157
51,226585,285,0.925,0.22118635904788972
52,209890,264,0.932,0.2114444851875305
53,221815,279,0.925,0.2165135760307312
54,273490,344,0.928,0.21592260003089905
55,280645,353,0.931,0.19500530767440796
56,358555,451,0.928,0.20106078851222992
57,305290,384,0.929,0.21384482395648957
58,194785,245,0.934,0.22120101308822632
59,177295,223,0.933,0.21015343022346497
60,161395,203,0.923,0.23496934461593627
61,151060,190,0.917,0.2258076674938202
62,232945,293,0.935,0.20116107368469238
63,196375,247,0.927,0.22560621225833893
64,245665,309,0.931,0.21318150389194487
65,271105,341,0.929,0.20855799221992494
66,242485,305,0.93,0.21997662043571473
67,222610,280,0.933,0.20616613972187042
68,231355,291,0.94,0.19778240275382997
69,320395,403,0.932,0.21317416095733643
70,273490,344,0.936,0.20117924153804778
71,365710,460,0.934,0.20702114272117614
72,359350,452,0.934,0.18694130623340607
73,294160,370,0.93,0.19993121457099913
74,352990,444,0.934,0.19784514600038527
75,400690,504,0.933,0.2049896411895752
76,453160,570,0.934,0.20656820285320282
77,453160,570,0.94,0.1888851979970932
78,496885,625,0.936,0.19560533905029298
79,566845,713,0.935,0.19802583438158036
80,441235,555,0.937,0.18189887607097627
81,505630,636,0.932,0.22395052230358123
82,633625,797,0.937,0.1914539303779602
83,510400,642,0.925,0.2161967045068741
