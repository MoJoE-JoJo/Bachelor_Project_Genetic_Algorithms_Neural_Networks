Experiment 2 ,08_03_2020_01-43-15

Data shape and running
input_shape ,"(28, 28)"
output_shape ,10
scaling ,255.0
epochs ,5
max_runtime,1800
dataset_percentage,0.1
dataset,mnist

Hyper parameters
activation_function ,Activation.relu
initial_max_nodes ,50
loss_function ,Loss.sparse_categorical_crossentropy
optimizer ,Optimizer.Adam

GA parameters
population_size ,10
mating_pool ,10
mutation_rate,0.3

OUTPUT
generation_no,params_no,neurons_no,accuracy,loss
0,38170,48,0.905,0.30423869848251345
1,29425,37,0.9,0.31537867879867554
2,29425,37,0.897,0.31186143255233767
3,19885,25,0.891,0.34213756561279296
4,15115,19,0.903,0.32317734956741334
5,15115,19,0.899,0.33318039894104
6,15910,20,0.892,0.3486651010513306
7,15910,20,0.894,0.33945406770706177
8,19885,25,0.9,0.3286260495185852
9,19885,25,0.896,0.3337076225280762
10,17500,22,0.896,0.34178976964950564
11,15910,20,0.893,0.3391229038238525
12,17500,22,0.907,0.32782472038269045
13,10345,13,0.889,0.38892901277542113
14,11140,14,0.892,0.36130414056777954
15,13525,17,0.893,0.35958777952194215
16,16705,21,0.891,0.3466998462677002
17,19090,24,0.899,0.3233122634887695
18,15910,20,0.886,0.3451156282424927
19,15115,19,0.896,0.33325473642349246
20,19090,24,0.89,0.35555373191833495
21,17500,22,0.891,0.34031955671310427
22,16705,21,0.897,0.33867038583755493
23,17500,22,0.899,0.3446038732528687
24,22270,28,0.907,0.3145890336036682
25,12730,16,0.887,0.3682465195655823
26,14320,18,0.89,0.3561759738922119
27,11140,14,0.88,0.3937986330986023
28,10345,13,0.886,0.3734531831741333
29,15910,20,0.896,0.3390569500923157
30,15910,20,0.906,0.3264305520057678
31,16705,21,0.889,0.36485636949539185
32,16705,21,0.891,0.3436174702644348
33,17500,22,0.899,0.3197401766777039
34,13525,17,0.888,0.365831289768219
35,17500,22,0.901,0.3451664001941681
36,19885,25,0.903,0.32475345087051394
37,19885,25,0.89,0.3418278732299805
38,16705,21,0.899,0.34614863109588623
39,14320,18,0.89,0.3618586082458496
40,16705,21,0.898,0.34500626516342164
41,17500,22,0.897,0.3508246648311615
42,22270,28,0.896,0.32426694631576536
43,14320,18,0.891,0.35446599626541136
44,13525,17,0.885,0.3395291986465454
45,17500,22,0.891,0.3463572907447815
46,15910,20,0.899,0.3244069209098816
47,18295,23,0.891,0.34689260053634646
48,18295,23,0.893,0.33931387710571287
49,18295,23,0.905,0.31803485298156736
50,21475,27,0.892,0.3440058560371399
51,21475,27,0.891,0.36275180864334106
52,19090,24,0.896,0.34233526849746704
53,19885,25,0.899,0.32005138540267947
54,27040,34,0.901,0.32082729959487916
55,33400,42,0.902,0.3098332991600037
56,27835,35,0.904,0.3190919599533081
57,34990,44,0.91,0.28834769868850707
58,34990,44,0.904,0.2942470469474793
59,17500,22,0.893,0.34583556842803953
60,15910,20,0.889,0.35985095930099487
61,14320,18,0.893,0.3458404612541199
62,18295,23,0.893,0.34489032077789306
63,14320,18,0.901,0.33684936952590944
64,17500,22,0.89,0.3458263988494873
65,15115,19,0.889,0.34543566608428955
66,13525,17,0.889,0.35672798204421996
67,13525,17,0.9,0.34597761869430543
68,12730,16,0.897,0.36046674132347106
69,10345,13,0.876,0.39339972257614136
70,9550,12,0.884,0.38927101278305054
71,11935,15,0.876,0.3771936783790588
72,14320,18,0.898,0.34210753297805785
73,15910,20,0.888,0.35664122200012205
74,15910,20,0.896,0.3291166319847107
75,14320,18,0.892,0.36267138385772707
76,8755,11,0.875,0.40399186086654665
77,9550,12,0.883,0.3854439973831177
78,7960,10,0.877,0.3934446740150452
79,7960,10,0.888,0.42542482280731203
80,7960,10,0.877,0.3995973496437073
81,8755,11,0.878,0.4078074088096619
82,10345,13,0.9,0.3598302240371704
83,12730,16,0.894,0.3579758629798889
84,12730,16,0.901,0.34178814506530764
85,12730,16,0.885,0.36480638456344605
86,11935,15,0.885,0.3679820885658264
87,11935,15,0.885,0.369799569606781
88,12730,16,0.889,0.36448197937011717
