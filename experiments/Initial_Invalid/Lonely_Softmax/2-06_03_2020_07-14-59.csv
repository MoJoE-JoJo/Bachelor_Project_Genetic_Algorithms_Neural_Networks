Experiment 3 ,06_03_2020_07-14-59

Data shape and running
input_shape ,"(28, 28)"
output_shape ,10
scaling ,255.0
epochs ,5
max_runtime,3600
dataset_percentage,0.1
dataset,mnist

Hyper parameters
activation_function ,Activation.softmax
initial_max_nodes ,50
loss_function ,Loss.sparse_categorical_crossentropy
optimizer ,Optimizer.Adam

GA parameters
population_size ,10
mating_pool ,10
mutation_rate,0.3

OUTPUT
generation_no,params_no,neurons_no,accuracy,loss
0,38965,49,0.856,1.0825801181793213
1,40555,51,0.828,1.143243989944458
2,54865,69,0.811,1.1044125690460205
3,74740,94,0.767,1.1512169132232666
4,32605,41,0.804,1.1065072174072266
5,36580,46,0.795,1.166897813796997
6,65995,83,0.785,1.124869565963745
7,66790,84,0.835,1.1056072731018067
8,42145,53,0.846,1.115567126274109
9,68380,86,0.868,1.117888916015625
10,83485,105,0.863,1.0952425079345702
11,104155,131,0.868,1.0743558101654054
12,124030,156,0.845,1.1242892208099364
13,124030,156,0.799,1.1431882724761964
14,86665,109,0.887,1.0713263931274415
15,124030,156,0.865,1.0839888782501221
16,68380,86,0.882,1.0817796154022217
17,127210,160,0.871,1.0755149745941162
18,147085,185,0.879,1.0745914306640625
19,241690,304,0.849,1.119812379837036
20,229765,289,0.816,1.0981106491088868
21,306085,385,0.877,1.1015388584136963
22,314830,396,0.882,1.086856665611267
23,259975,327,0.886,1.0829288387298583
24,191605,241,0.851,1.1064932498931885
25,318805,401,0.86,1.1254930248260497
26,229765,289,0.865,1.0770541000366212
27,398305,501,0.858,1.1142947883605958
28,300520,378,0.883,1.0789994106292724
29,440440,554,0.886,1.0648966846466064
30,449185,565,0.851,1.1245379085540772
31,709945,893,0.843,1.109702476501465
32,196375,247,0.84,1.1137758474349975
33,223405,281,0.872,1.1214309177398682
34,546175,687,0.835,1.1270250205993653
35,461905,581,0.885,1.0925578269958496
36,370480,466,0.886,1.0912117137908937
37,1101880,1386,0.89,1.0822428674697877
38,461905,581,0.832,1.1340751266479492
39,109720,138,0.888,1.0794879398345947
40,217045,273,0.881,1.0725144510269164
41,612160,770,0.88,1.0529714241027832
42,281440,354,0.819,1.1113309412002563
43,315625,397,0.879,1.1011555976867675
44,731410,920,0.887,1.090676263809204
45,372070,468,0.814,1.1173575458526612
46,894385,1125,0.846,1.119075159072876
47,847480,1066,0.806,1.139629711151123
48,1222720,1538,0.822,1.0963192319869994
49,941290,1184,0.883,1.0976145915985107
50,804550,1012,0.865,1.0905234661102294
51,1041460,1310,0.825,1.1101947193145751
52,1486660,1870,0.884,1.0603440990447999
53,1326070,1668,0.816,1.120387912750244
54,1304605,1641,0.869,1.0828688049316406
55,1013635,1275,0.828,1.125131139755249
56,875305,1101,0.884,1.0952901029586792
57,1348330,1696,0.84,1.11754398727417
58,3001930,3776,0.825,1.1035582256317138
59,2094040,2634,0.832,1.1172433204650878
60,3123565,3929,0.818,1.113890007019043
61,3323110,4180,0.818,1.1085856304168702
62,3282565,4129,0.865,1.09257905960083
63,3123565,3929,0.804,1.1327229948043824
64,5929915,7459,0.81,1.1065002422332764
65,3254740,4094,0.879,1.0715270547866822
66,3254740,4094,0.878,1.1003788223266602
67,3598180,4526,0.883,1.0926119060516357
68,5608735,7055,0.834,1.1141832723617553
69,5005330,6296,0.878,1.0806384105682374
70,9424735,11855,0.821,1.0754073390960692
71,11161015,14039,0.889,1.0498359479904176
72,6930820,8718,0.82,1.104760639190674
73,6429175,8087,0.839,1.1162626457214355
74,4132420,5198,0.873,1.0605840711593628
75,14501605,18241,0.824,1.0873016214370728
76,6604870,8308,0.879,1.0805301637649536
