Experiment 2 ,06_03_2020_06-14-59

Data shape and running
input_shape ,"(28, 28)"
output_shape ,10
scaling ,255.0
epochs ,5
max_runtime,3600
dataset_percentage,0.1
dataset,mnist

Hyper parameters
activation_function ,Activation.softmax
initial_max_nodes ,50
loss_function ,Loss.sparse_categorical_crossentropy
optimizer ,Optimizer.Adam

GA parameters
population_size ,10
mating_pool ,10
mutation_rate,0.3

OUTPUT
generation_no,params_no,neurons_no,accuracy,loss
0,15115,19,0.806,1.1214910259246826
1,23860,30,0.801,1.1374824275970459
2,49300,62,0.802,1.115089807510376
3,21475,27,0.764,1.1343540697097778
4,23860,30,0.876,1.082340799331665
5,72355,91,0.822,1.1038658180236816
6,33400,42,0.829,1.0849792785644532
7,31810,40,0.878,1.067516180038452
8,68380,86,0.832,1.1105656204223633
9,49300,62,0.78,1.1573513803482056
10,33400,42,0.78,1.1390785942077637
11,53275,67,0.851,1.1038865547180177
12,64405,81,0.85,1.0743441743850708
13,68380,86,0.88,1.0663959989547729
14,98590,124,0.887,1.0937483024597168
15,45325,57,0.813,1.0992253637313842
16,53275,67,0.819,1.110828971862793
17,183655,231,0.823,1.1049729156494141
18,72355,91,0.839,1.1231308479309081
19,125620,158,0.886,1.0900685043334961
20,126415,159,0.844,1.1093774929046631
21,186835,235,0.828,1.099363561630249
22,87460,110,0.858,1.0983856449127196
23,112105,141,0.813,1.1186776542663575
24,107335,135,0.832,1.1158121833801269
25,141520,178,0.876,1.0728007917404174
26,143905,181,0.883,1.0953949756622314
27,213070,268,0.894,1.0938723964691162
28,205915,259,0.859,1.1368021545410156
29,205915,259,0.832,1.109075511932373
30,217045,273,0.823,1.1189997463226318
31,187630,236,0.845,1.114752742767334
32,255205,321,0.878,1.1055929374694824
33,180475,227,0.858,1.1215465965270996
34,487345,613,0.882,1.0856745071411134
35,172525,217,0.847,1.0951477737426758
36,277465,349,0.803,1.1538256130218505
37,304495,383,0.807,1.140936632156372
38,283825,357,0.874,1.089315216064453
39,911080,1146,0.885,1.078780117034912
40,321190,404,0.857,1.0883268508911133
41,403075,507,0.831,1.1259221334457397
42,599440,754,0.84,1.1288718824386597
43,615340,774,0.816,1.1021510524749756
44,1159120,1458,0.846,1.1059759607315063
45,1369000,1722,0.88,1.0690567770004273
46,1653610,2080,0.84,1.0940769500732421
47,1780015,2239,0.833,1.0965106248855592
48,1799890,2264,0.865,1.1185150938034059
49,2275300,2862,0.87,1.0849115352630616
50,1709260,2150,0.884,1.0815104541778564
51,3715045,4673,0.832,1.0923547019958497
52,3672115,4619,0.823,1.1371678581237794
53,4395565,5529,0.811,1.136369746208191
54,2149690,2704,0.805,1.147007766723633
55,4291420,5398,0.894,1.0530189933776855
56,1528795,1923,0.829,1.1299034900665283
57,4487785,5645,0.858,1.0960174074172975
58,7724230,9716,0.855,1.0853606252670287
59,4870975,6127,0.868,1.084187068939209
60,4517995,5683,0.886,1.0626771926879883
61,3196705,4021,0.883,1.0581981010437012
62,4902775,6167,0.826,1.1279251775741577
63,4451215,5599,0.83,1.1239493045806885
64,5627815,7079,0.845,1.1155175876617431
65,8081980,10166,0.873,1.0472800979614258
66,10897075,13707,0.82,1.1129493713378906
67,8899240,11194,0.81,1.1292663946151733
68,5226340,6574,0.814,1.093212703704834
69,11150680,14026,0.815,1.1307973327636718
70,3866095,4863,0.85,1.0684758195877075
