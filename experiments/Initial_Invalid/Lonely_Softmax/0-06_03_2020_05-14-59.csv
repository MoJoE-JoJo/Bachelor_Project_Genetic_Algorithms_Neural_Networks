Experiment 1 ,06_03_2020_05-14-59

Data shape and running
input_shape ,"(28, 28)"
output_shape ,10
scaling ,255.0
epochs ,5
max_runtime,3600
dataset_percentage,0.1
dataset,mnist

Hyper parameters
activation_function ,Activation.softmax
initial_max_nodes ,50
loss_function ,Loss.sparse_categorical_crossentropy
optimizer ,Optimizer.Adam

GA parameters
population_size ,10
mating_pool ,10
mutation_rate,0.3

OUTPUT
generation_no,params_no,neurons_no,accuracy,loss
0,32605,41,0.771,1.1488223304748535
1,25450,32,0.791,1.1660796155929565
2,60430,76,0.803,1.099563307762146
3,28630,36,0.812,1.0901771993637086
4,51685,65,0.84,1.11851575756073
5,75535,95,0.774,1.151580535888672
6,31015,39,0.83,1.0933271293640137
7,23860,30,0.843,1.0992524223327638
8,19090,24,0.756,1.1749466609954835
9,23860,30,0.819,1.0964751091003417
10,34195,43,0.82,1.0898606052398683
11,61225,77,0.805,1.112032769203186
12,50095,63,0.875,1.0694879999160767
13,52480,66,0.833,1.0976336240768432
14,117670,148,0.788,1.1408033895492553
15,49300,62,0.82,1.0803321437835693
16,100975,127,0.78,1.1458700170516969
17,38965,49,0.789,1.1336587543487548
18,79510,100,0.872,1.0935179862976074
19,99385,125,0.844,1.101604154586792
20,267925,337,0.878,1.0719540815353394
21,132775,167,0.828,1.1502228832244874
22,79510,100,0.845,1.0923743467330933
23,171730,216,0.891,1.0496072111129762
24,143905,181,0.813,1.1199074354171752
25,104155,131,0.879,1.089898108482361
26,109720,138,0.863,1.0761461143493651
27,67585,85,0.83,1.1137481298446654
28,94615,119,0.847,1.0963323125839233
29,124030,156,0.802,1.159571665763855
30,376045,473,0.849,1.1015102005004882
31,151855,191,0.829,1.120007875442505
32,217045,273,0.851,1.1127732009887696
33,110515,139,0.865,1.0939708576202392
34,214660,270,0.843,1.1111796312332154
35,120850,152,0.841,1.1129807291030884
36,162985,205,0.887,1.078347463607788
37,88255,111,0.848,1.0962037467956542
38,78715,99,0.848,1.0859605016708374
39,62020,78,0.822,1.0858190460205077
40,69970,88,0.848,1.1028760471343995
41,170140,214,0.835,1.0879238739013672
42,227380,286,0.848,1.1168564147949218
43,45325,57,0.823,1.117720869064331
44,104950,132,0.833,1.145501042366028
45,300520,378,0.839,1.1244899759292601
46,300520,378,0.886,1.0718058347702026
47,99385,125,0.841,1.1057315559387206
48,427720,538,0.834,1.1315254201889038
49,90640,114,0.849,1.0936425876617433
50,110515,139,0.816,1.1146421518325806
51,84280,106,0.886,1.0593442077636719
52,81895,103,0.846,1.0883258533477784
53,682120,858,0.838,1.122215280532837
54,1170250,1472,0.88,1.098061484336853
55,1036690,1304,0.883,1.0830209197998046
56,1258495,1583,0.888,1.0728063154220582
57,1610680,2026,0.815,1.1182432985305786
58,1318915,1659,0.837,1.098028591156006
59,1318915,1659,0.872,1.0840542783737184
60,2677570,3368,0.856,1.0972098350524901
61,1230670,1548,0.85,1.1420568332672119
62,1473940,1854,0.863,1.1030567140579224
63,985810,1240,0.874,1.0678353309631348
64,1106650,1392,0.892,1.0841809406280518
65,2734015,3439,0.816,1.1039400272369384
66,129595,163,0.842,1.0860522241592407
67,2784100,3502,0.824,1.123791955947876
68,2207725,2777,0.88,1.089163875579834
69,2866780,3606,0.86,1.1063565082550049
70,2787280,3506,0.828,1.1057218732833862
71,1687000,2122,0.805,1.1169781379699708
72,2256220,2838,0.88,1.0931075525283813
73,4629295,5823,0.88,1.0613075790405273
74,1842025,2317,0.812,1.1240913982391358
75,1842025,2317,0.877,1.0888038740158081
76,5228725,6577,0.883,1.0548515768051148
77,1702900,2142,0.838,1.1164055938720703
78,2951050,3712,0.825,1.1100848684310913
79,1702900,2142,0.816,1.1330576677322388
80,1398415,1759,0.804,1.1364096183776855
81,1589215,1999,0.87,1.100259033203125
82,2631460,3310,0.831,1.121160816192627
83,4088695,5143,0.832,1.1018902530670167
84,4088695,5143,0.891,1.0702617378234864
85,4670635,5875,0.881,1.076017593383789
